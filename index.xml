<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The Danger Zone</title>
    <link>https://therealmjp.github.io/</link>
    <description>Recent content on The Danger Zone</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://therealmjp.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Publications</title>
      <link>https://therealmjp.github.io/publications/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/publications/</guid>
      <description>Breaking Down Barriers: An Introduction To GPU Synchronization – from the Advanced Graphics Techniques tutorial session at GDC 2019
Slides
 Advanced Lighting R&amp;amp;D at Ready At Dawn Studios – from the Physically Based Shading in Theory and Practice course at SIGGRAPH 2015
Course Page
Slides (pptx)
Slides (pdf)
 Rendering The Alternate History of The Order: 1886 – from the Advances in Real-Time Rendering in Games course at SIGGRAPH 2015</description>
    </item>
    
    <item>
      <title>About This Site</title>
      <link>https://therealmjp.github.io/about/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/about/</guid>
      <description>My name is Matt, and I’m the lead graphics/engine programmer for Ready At Dawn Studios. I usually go by &amp;ldquo;MJP&amp;rdquo; on the internet.
This site is mainly for blog, where I mostly post about things related to graphics and game programming.</description>
    </item>
    
    <item>
      <title>Test Blog Post</title>
      <link>https://therealmjp.github.io/posts/test/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/test/</guid>
      <description>Hello there! Here&amp;rsquo;s some inline math: \( \int x^3 dx \)
And here&amp;rsquo;s some centered math:
$$\int_{a}^{b} x^2 dx$$
And now for some code!
void DoSomething() { Whatever(); for(int i = 0; i &amp;lt; 10; ++i) { auto x = i * 2; printf(&amp;#34;i&amp;#34;, x); } }  How about a cool image?
Conclusion This has been a great test.</description>
    </item>
    
    <item>
      <title>Adventures in Retro Development: SNES Edition</title>
      <link>https://therealmjp.github.io/posts/adventures-in-retro-development-snes-edition/</link>
      <pubDate>Tue, 15 Jan 2019 05:36:42 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/adventures-in-retro-development-snes-edition/</guid>
      <description>When I was growing up, the SNES was easily my favorite console. How could it not be, with top-tier games like Super Metroid and Mega Man X available? I had always wanted to learn how to program for the SNES so that I could develop my own silly games for the hardware that ran my favorite games as a kid. I decided to use this past holiday break as an excuse to finally get started, and I had a great time doing it!</description>
    </item>
    
    <item>
      <title>Breaking Down Barriers - Part 6: Experimenting With Overlap and Preemption</title>
      <link>https://therealmjp.github.io/posts/breaking-down-barriers-part-6-experimenting-with-overlap-and-preemption/</link>
      <pubDate>Mon, 10 Dec 2018 02:01:27 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/breaking-down-barriers-part-6-experimenting-with-overlap-and-preemption/</guid>
      <description>This is Part 6 of a series about GPU synchronization and preemption. You can find the other articles here:
Part 1 - What&amp;rsquo;s a Barrier?
Part 2 - Synchronizing GPU Threads
Part 3 - Multiple Command Processors
Part 4 - GPU Preemption
Part 5 - Back To The Real World
Part 6 - Experimenting With Overlap and Preemption
In the previous art_icl_es we took a look at how barriers typically work on GPUs, and then we examined how multiple hardware queues can help with preemption and overall throughput.</description>
    </item>
    
    <item>
      <title>Breaking Down Barriers – Part 5: Back To The Real World</title>
      <link>https://therealmjp.github.io/posts/breaking-down-barriers-part-5-back-to-the-real-world/</link>
      <pubDate>Sun, 09 Sep 2018 00:48:18 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/breaking-down-barriers-part-5-back-to-the-real-world/</guid>
      <description>This is Part 5 of a series about GPU synchronization and preemption. You can find the other articles here:
Part 1 - What&amp;rsquo;s a Barrier?
Part 2 - Synchronizing GPU Threads
Part 3 - Multiple Command Processors
Part 4 - GPU Preemption
Part 5 - Back To The Real World
Part 6 - Experimenting With Overlap and Preemption
Welcome to part 5 of the series! If you&amp;rsquo;ve read all of the articles so far, thanks for hanging in there!</description>
    </item>
    
    <item>
      <title>Breaking Down Barriers - Part 4: GPU Preemption</title>
      <link>https://therealmjp.github.io/posts/breaking-down-barriers-part-4-gpu-preemption/</link>
      <pubDate>Wed, 04 Jul 2018 00:57:43 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/breaking-down-barriers-part-4-gpu-preemption/</guid>
      <description>This is Part 4 of a series about GPU synchronization and preemption. You can find the other articles here:
Part 1 - What&amp;rsquo;s a Barrier?
Part 2 - Synchronizing GPU Threads
Part 3 - Multiple Command Processors
Part 4 - GPU Preemption
Part 5 - Back To The Real World
Part 6 - Experimenting With Overlap and Preemption
Welcome back! For the past two articles we&amp;rsquo;ve been taking a in-depth look at how a fictional GPU converts command buffers into lots of shader threads, and also how synchronization of those threads affects the overall performance of the GPU.</description>
    </item>
    
    <item>
      <title>Breaking Down Barriers - Part 3: Multiple Command Processors</title>
      <link>https://therealmjp.github.io/posts/breaking-down-barriers-part-3-multiple-command-processors/</link>
      <pubDate>Mon, 18 Jun 2018 02:14:52 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/breaking-down-barriers-part-3-multiple-command-processors/</guid>
      <description>This is Part 3 of a series about GPU synchronization and preemption. You can find the other articles here:
Part 1 - What&amp;rsquo;s a Barrier?
Part 2 - Synchronizing GPU Threads
Part 3 - Multiple Command Processors
Part 4 - GPU Preemption
Part 5 - Back To The Real World
Part 6 - Experimenting With Overlap and Preemption
Welcome to Part 3 of the series! In this article, I&amp;rsquo;m going to talk a bit about how multiple command processors can be used to increase the overall performance of a GPU by reducing the amount of time that shader cores sit idle.</description>
    </item>
    
    <item>
      <title>Breaking Down Barriers - Part 2: Synchronizing GPU Threads</title>
      <link>https://therealmjp.github.io/posts/breaking-down-barriers-part-2-synchronizing-gpu-threads/</link>
      <pubDate>Mon, 02 Apr 2018 06:29:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/breaking-down-barriers-part-2-synchronizing-gpu-threads/</guid>
      <description>This is Part 2 of a series about GPU synchronization and preemption. You can find the other articles here:
Part 1 - What&amp;rsquo;s a Barrier?
Part 2 - Synchronizing GPU Threads
Part 3 - Multiple Command Processors
Part 4 - GPU Preemption
Part 5 - Back To The Real World
Part 6 - Experimenting With Overlap and Preemption
Welcome to part 2 of the series! In the previous article, I explained the basics of what a barrier is, and talked about the various reasons for why you need to use a barrier on a GPU.</description>
    </item>
    
    <item>
      <title>Breaking Down Barriers - Part 1: What&#39;s a Barrier?</title>
      <link>https://therealmjp.github.io/posts/breaking-down-barriers-part-1-whats-a-barrier/</link>
      <pubDate>Tue, 06 Mar 2018 09:21:34 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/breaking-down-barriers-part-1-whats-a-barrier/</guid>
      <description>This is Part 1 of a series about GPU synchronization and preemption. You can find the other articles here:
Part 1 - What&amp;rsquo;s a Barrier?
Part 2 - Synchronizing GPU Threads
Part 3 - Multiple Command Processors
Part 4 - GPU Preemption
Part 5 - Back To The Real World
Part 6 - Experimenting With Overlap and Preemption
If you&amp;rsquo;ve done any amount of D3D12 or Vulkan programming, then you&amp;rsquo;ve probably spent a good bit of that time grappling with barriers.</description>
    </item>
    
    <item>
      <title>SG Series Part 6: Step Into The Baking Lab</title>
      <link>https://therealmjp.github.io/posts/sg-series-part-6-step-into-the-baking-lab/</link>
      <pubDate>Mon, 10 Oct 2016 07:13:58 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sg-series-part-6-step-into-the-baking-lab/</guid>
      <description>This is part 6 of a series on Spherical Gaussians and their applications for pre-computed lighting. You can find the other articles here:
Part 1 - A Brief (and Incomplete) History of Baked Lighting Representations
Part 2 - Spherical Gaussians 101
Part 3 - Diffuse Lighting From an SG Light Source
Part 4 - Specular Lighting From an SG Light Source
Part 5 - Approximating Radiance and Irradiance With SG&amp;rsquo;s</description>
    </item>
    
    <item>
      <title>SG Series Part 5: Approximating Radiance and Irradiance With SG&#39;s</title>
      <link>https://therealmjp.github.io/posts/sg-series-part-5-approximating-radiance-and-irradiance-with-sgs/</link>
      <pubDate>Mon, 10 Oct 2016 07:12:13 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sg-series-part-5-approximating-radiance-and-irradiance-with-sgs/</guid>
      <description>This is part 5 of a series on Spherical Gaussians and their applications for pre-computed lighting. You can find the other articles here:
Part 1 - A Brief (and Incomplete) History of Baked Lighting Representations
Part 2 - Spherical Gaussians 101
Part 3 - Diffuse Lighting From an SG Light Source
Part 4 - Specular Lighting From an SG Light Source
Part 5 - Approximating Radiance and Irradiance With SG&amp;rsquo;s</description>
    </item>
    
    <item>
      <title>SG Series Part 4: Specular Lighting From an SG Light Source</title>
      <link>https://therealmjp.github.io/posts/sg-series-part-4-specular-lighting-from-an-sg-light-source/</link>
      <pubDate>Mon, 10 Oct 2016 07:09:20 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sg-series-part-4-specular-lighting-from-an-sg-light-source/</guid>
      <description>This is part 4 of a series on Spherical Gaussians and their applications for pre-computed lighting. You can find the other articles here:
Part 1 - A Brief (and Incomplete) History of Baked Lighting Representations
Part 2 - Spherical Gaussians 101
Part 3 - Diffuse Lighting From an SG Light Source
Part 4 - Specular Lighting From an SG Light Source
Part 5 - Approximating Radiance and Irradiance With SG&amp;rsquo;s</description>
    </item>
    
    <item>
      <title>SG Series Part 3: Diffuse Lighting From an SG Light Source</title>
      <link>https://therealmjp.github.io/posts/sg-series-part-3-diffuse-lighting-from-an-sg-light-source/</link>
      <pubDate>Mon, 10 Oct 2016 07:08:51 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sg-series-part-3-diffuse-lighting-from-an-sg-light-source/</guid>
      <description>This is part 3 of a series on Spherical Gaussians and their applications for pre-computed lighting. You can find the other articles here:
Part 1 - A Brief (and Incomplete) History of Baked Lighting Representations
Part 2 - Spherical Gaussians 101
Part 3 - Diffuse Lighting From an SG Light Source
Part 4 - Specular Lighting From an SG Light Source
Part 5 - Approximating Radiance and Irradiance With SG&amp;rsquo;s</description>
    </item>
    
    <item>
      <title>SG Series Part 2: Spherical Gaussians 101</title>
      <link>https://therealmjp.github.io/posts/sg-series-part-2-spherical-gaussians-101/</link>
      <pubDate>Mon, 10 Oct 2016 07:08:02 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sg-series-part-2-spherical-gaussians-101/</guid>
      <description>This is part 2 of a series on Spherical Gaussians and their applications for pre-computed lighting. You can find the other articles here:
Part 1 - A Brief (and Incomplete) History of Baked Lighting Representations
Part 2 - Spherical Gaussians 101
Part 3 - Diffuse Lighting From an SG Light Source
Part 4 - Specular Lighting From an SG Light Source
Part 5 - Approximating Radiance and Irradiance With SG&amp;rsquo;s</description>
    </item>
    
    <item>
      <title>SG Series Part 1: A Brief (and Incomplete) History of Baked Lighting Representations</title>
      <link>https://therealmjp.github.io/posts/sg-series-part-1-a-brief-and-incomplete-history-of-baked-lighting-representations/</link>
      <pubDate>Mon, 10 Oct 2016 07:05:49 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sg-series-part-1-a-brief-and-incomplete-history-of-baked-lighting-representations/</guid>
      <description>This is part 1 of a series on Spherical Gaussians and their applications for pre-computed lighting. You can find the other articles here:
Part 1 - A Brief (and Incomplete) History of Baked Lighting Representations
Part 2 - Spherical Gaussians 101
Part 3 - Diffuse Lighting From an SG Light Source
Part 4 - Specular Lighting From an SG Light Source
Part 5 - Approximating Radiance and Irradiance With SG&amp;rsquo;s</description>
    </item>
    
    <item>
      <title>New Blog Series: Lightmap Baking and Spherical Gaussians</title>
      <link>https://therealmjp.github.io/posts/new-blog-series-lightmap-baking-and-spherical-gaussians/</link>
      <pubDate>Mon, 10 Oct 2016 07:05:10 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/new-blog-series-lightmap-baking-and-spherical-gaussians/</guid>
      <description>So nearly year and a half ago myself and Dave Neubelt gave a presentation at SIGGRAPH where we described the approach that we developed for approximating incoming radiance using Spherical Gaussians in both our lightmaps and 3D probe grids. We had planned on releasing a source code demo as well as course notes that would serve as a full set of implementation details, but unfortunately those efforts were sidetracked by other responsibilities.</description>
    </item>
    
    <item>
      <title>Bindless Texturing for Deferred Rendering and Decals</title>
      <link>https://therealmjp.github.io/posts/bindless-texturing-for-deferred-rendering-and-decals/</link>
      <pubDate>Fri, 25 Mar 2016 08:39:36 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/bindless-texturing-for-deferred-rendering-and-decals/</guid>
      <description>https://github.com/TheRealMJP/DeferredTexturing
https://github.com/TheRealMJP/DeferredTexturing/releases (Precompiled Binaries)
To Bind, or Not To Bind Unless you&amp;rsquo;ve been in a coma for the past year, you&amp;rsquo;ve probably noticed that there&amp;rsquo;s a lot of buzz and excitement around the new graphics API&amp;rsquo;s that are available for PC and mobile. One of the biggest changes brought by both D3D12 and Vulkan is that they&amp;rsquo;ve ditched the old slot-based system for binding resources that&amp;rsquo;s been in use since&amp;hellip;forever.</description>
    </item>
    
    <item>
      <title>Update For My Shadow Sample Update</title>
      <link>https://therealmjp.github.io/posts/update-for-my-shadow-sample-update/</link>
      <pubDate>Mon, 25 Jan 2016 00:24:56 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/update-for-my-shadow-sample-update/</guid>
      <description>Recently I was contacted by Christoph Peters (one of the authors of Moment Shadow Mapping) regarding a blog post where I compared EVSM to MSM using my sample app. He noticed that I was incorrectly clamping the maximum exponential warp to 10.0 for the 16-bit variant of EVSM, which can result in values that are greater than what can be stored in a 16-bit floating point texture. Doing this has 2 effects: it causes incorrect results during filtering (clamping the moments can lead to negative variance, causing a reconstruction that resembles a step function), and it reduces the amount of light bleeding.</description>
    </item>
    
    <item>
      <title>Stairway To (Programmable Sample Point) Heaven</title>
      <link>https://therealmjp.github.io/posts/programmable-sample-points/</link>
      <pubDate>Mon, 14 Sep 2015 03:31:37 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/programmable-sample-points/</guid>
      <description>What Is and Should Never Be Historically, the sub-pixel location of MSAA sample points was totally out of your control as a programmer. Typically the hardware used rotated grid patterns such as this one, which were fixed for every pixel in your render target. For FEATURE_LEVEL_10_1, D3D added the concept of standard sample patterns that were required to be supported by the hardware. These were nice, in that you could specify the appropriate quality level and know exactly where the samples would be located.</description>
    </item>
    
    <item>
      <title>SIGGRAPH Follow-Up: 2015 Edition</title>
      <link>https://therealmjp.github.io/posts/siggraph-2015/</link>
      <pubDate>Mon, 17 Aug 2015 05:17:57 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/siggraph-2015/</guid>
      <description>SIGGRAPH 2015 wrapped up just a few days ago, and it really was fantastic this year! There was tons of great content, and I got a chance to meet up with some of best graphics programmers in the industry. I wanted to thank anyone that came to my talk at Advances in Real-Time Rendering, as well as anyone who came to our talk at the Physically Based Shading course. It&amp;rsquo;s always awesome to see so many people interested in the latest rendering technology, and the other presenters really knocked it out of the park in both courses.</description>
    </item>
    
    <item>
      <title>Mitsuba Quick-Start Guide</title>
      <link>https://therealmjp.github.io/posts/mitsuba-quick-start-guide/</link>
      <pubDate>Sat, 04 Apr 2015 20:36:44 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/mitsuba-quick-start-guide/</guid>
      <description>Angelo Pesce&amp;rsquo;s recent blog post brought up a great point towards the end of the article: having a &amp;ldquo;ground-truth&amp;rdquo; for comparison can be extremely important for evaluating your real-time techniques. For approximations like pre-integrated environment maps it can help visualize what kind of effect your approximation errors will have on a final rendered image, and and in many other cases it can aid you in tracking down bugs in your implementation.</description>
    </item>
    
    <item>
      <title>Some Special Thanks</title>
      <link>https://therealmjp.github.io/posts/some-special-thanks/</link>
      <pubDate>Mon, 23 Mar 2015 08:35:45 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/some-special-thanks/</guid>
      <description>About a month ago, a little game called The Order: 1886 finally hit store shelves. Its release marks the culmination of my past 4 years at Ready At Dawn, which were largely devoted to developing the core rendering and engine technology that was ultimately used for the game. It&amp;rsquo;s also a major milestone for me personally, as it&amp;rsquo;s the first project that I&amp;rsquo;ve worked on full-time from start to finish.</description>
    </item>
    
    <item>
      <title>Shadow Sample Update</title>
      <link>https://therealmjp.github.io/posts/shadow-sample-update/</link>
      <pubDate>Wed, 18 Feb 2015 18:00:06 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/shadow-sample-update/</guid>
      <description>Update 1/24/2016: one of the authors of the Moment Shadow Mapping paper contacted to let me know that there was an issue in my implementation of the 16-bit variant of EVSM. My sample app was clamping the maximum exponential warp factor to 10.0, which can result in overflow for a 16-bit float. This has the effect of reducing light bleeding, but it also causes edge quality to suffer during filtering.</description>
    </item>
    
    <item>
      <title>Come see me talk at GDC 2014</title>
      <link>https://therealmjp.github.io/posts/come-see-me-talk-at-gdc-2014/</link>
      <pubDate>Wed, 12 Mar 2014 06:49:11 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/come-see-me-talk-at-gdc-2014/</guid>
      <description>Myself and fellow lead graphics programmer David Neubelt will be at GDC next week, talking about the rendering technology behind The Order: 1886. Unfortunately the talk came together a bit late, and so it initially started from the talk that we gave back at SIGGRAPH at last year (which is why it has the same title). However we don&amp;rsquo;t want to just rehash the same material, so we&amp;rsquo;ve added tons of new slides and revamped the old ones.</description>
    </item>
    
    <item>
      <title>Weighted Blended Order-Independent Transparency</title>
      <link>https://therealmjp.github.io/posts/weighted-blended-oit/</link>
      <pubDate>Tue, 04 Feb 2014 06:58:04 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/weighted-blended-oit/</guid>
      <description>http://mynameismjp.files.wordpress.com/2014/02/blendedoit.zip
Back in December, Morgan McGuire and Louis Bavoil published a paper called Weighted Blended Order-Independent Transparency. In case you haven&amp;rsquo;t read it yet (you really should!), it proposes an OIT scheme that uses a weighted blend of all surfaces that overlap a given pixel. In other words finalColor = w0 * c0 + w1 * c1 + w2 * c2&amp;hellip;etc. With a weighted blend the order of rendering no longer matters, which frees you from the never-ending nightmare of sorting.</description>
    </item>
    
    <item>
      <title>Sample Framework Updates</title>
      <link>https://therealmjp.github.io/posts/sample-framework-updates/</link>
      <pubDate>Tue, 17 Sep 2013 05:54:02 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sample-framework-updates/</guid>
      <description>You may have noticed that my latest sample now has a proper UI instead of the homegrown sliders and keyboard toggles that I was using in my older samples. What you might not have noticed is that there&amp;rsquo;s a whole bunch of behind-the-scenes changes to go with that new UI! Before I ramble on, here&amp;rsquo;s a quick bullet-point list of the new features:
 Switched to VS2012 and adopted a few C++11 features New UI back-end provided by AntTweakBar C#-based data-definition format for auto-generating UI Shader hot-swapping Better shader caching, and compressed cache files  It occurred to me a little while ago that I could try to develop my framework into something that enables rapid prototyping, instead of just being some random bits of cobbled-together code.</description>
    </item>
    
    <item>
      <title>A Sampling of Shadow Techniques</title>
      <link>https://therealmjp.github.io/posts/shadow-maps/</link>
      <pubDate>Wed, 11 Sep 2013 07:45:40 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/shadow-maps/</guid>
      <description>A little over a year ago I was looking to overhaul our shadow rendering at work in order to improve overall quality, as well as simplify the workflow for the lighting artists (tweaking biases all day isn&amp;rsquo;t fun for anybody). After doing yet another round of research into modern shadow mapping techniques, I decided to do what I usually do and starting working on sample project that I could use as a platform for experimentation and comparison.</description>
    </item>
    
    <item>
      <title>DX11.2 Tiled Resources</title>
      <link>https://therealmjp.github.io/posts/dx11-2-tiled-resources/</link>
      <pubDate>Sat, 07 Sep 2013 06:21:28 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/dx11-2-tiled-resources/</guid>
      <description>Tiled resources seems to be the big-ticket item for the upcoming DX11.2 update. While the online documentation has some information about the new functions added to the API, there&amp;rsquo;s currently no information about the two tiers of tiled resource functionality being offered. Fortunately there is a sample app available that provides some clues. After poking around a bit last night, these were the differences that I noticed:
 TIER2 supports MIN and MAX texture sampling modes that return the min or max of 4 neighboring texels.</description>
    </item>
    
    <item>
      <title>SIGGRAPH Follow-Up</title>
      <link>https://therealmjp.github.io/posts/siggraph-follow-up/</link>
      <pubDate>Mon, 29 Jul 2013 06:15:04 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/siggraph-follow-up/</guid>
      <description>So I&amp;rsquo;m hoping that if you&amp;rsquo;re reading this, you&amp;rsquo;ve already attended or read the slides from my presentation about The Order: 1886 that was part of the Physically Based Shading Course at SIGGRAPH last week. If not, go grab them and get started! If you haven&amp;rsquo;t read through the course notes already there&amp;rsquo;s a lot of good info there, in fact there&amp;rsquo;s almost 30 pages worth! The highlights include:</description>
    </item>
    
    <item>
      <title>What I&#39;ve been working on for the past 2 years</title>
      <link>https://therealmjp.github.io/posts/what-ive-been-working-on/</link>
      <pubDate>Wed, 12 Jun 2013 07:48:45 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/what-ive-been-working-on/</guid>
      <description>The announce trailer for Ready At Dawn&amp;rsquo;s latest project was shown during Sony&amp;rsquo;s E3 press conference yesterday, but if you missed it you can watch it here. There&amp;rsquo;s also a few full-res screenshots available here, with less compress-o-vision. It feels really good to finally be able to tell people what game I&amp;rsquo;ve been working on, and that we&amp;rsquo;re making a PS4 title. I&amp;rsquo;m also insanely proud of the trailer itself, as well as the in-house tech we&amp;rsquo;ve developed that made it possible.</description>
    </item>
    
    <item>
      <title>HLSL User Defined Language for Notepad&#43;&#43;</title>
      <link>https://therealmjp.github.io/posts/hlsl-udl/</link>
      <pubDate>Mon, 05 Nov 2012 07:09:39 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/hlsl-udl/</guid>
      <description>When it comes to writing shaders, Notepad++ is currently my editor of choice. The most recent release of Notepad++ added version 2.0 of their User Defined Language (UDL) system, which adds quite a few improvements. I&amp;rsquo;ve been using an HLSL UDL file that I downloaded from somewhere else for a while now, and I decided to upgrade it to the 2.0 format and also make it work better for SM5.</description>
    </item>
    
    <item>
      <title>Experimenting with Reconstruction Filters for MSAA Resolve</title>
      <link>https://therealmjp.github.io/posts/msaa-resolve-filters/</link>
      <pubDate>Mon, 29 Oct 2012 07:33:31 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-resolve-filters/</guid>
      <description>Previous article in the series: A Quick Overview of MSAA
Update 8/26/2017: while working on The Order I improved upon the work described here, which I presented at SIGGRAPH 2015. I also created an updated MSAA + TAA filtering demo that you can find on GitHub, which just about completely supersedes the demo that&amp;rsquo;s linked at the end of the article. So make sure that you look at the new one as well!</description>
    </item>
    
    <item>
      <title>A Quick Overview of MSAA</title>
      <link>https://therealmjp.github.io/posts/msaa-overview/</link>
      <pubDate>Thu, 25 Oct 2012 07:03:27 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-overview/</guid>
      <description>Previous article in the series: Applying Sampling Theory to Real-Time Graphics
Updated 1/27/2016 - replaced the MSAA partial coverage image with a new image that illustrates subsamples being written to, as suggested by Simon Trümpler.
MSAA can be a bit complicated, due to the fact that it affects nearly the entire rasterization pipeline used in GPU’s. It’s also complicated because really understanding why it works requires at least a basic understanding of signal processing and image resampling.</description>
    </item>
    
    <item>
      <title>Applying Sampling Theory To Real-Time Graphics</title>
      <link>https://therealmjp.github.io/posts/applying-sampling-theory-to-real-time-graphics/</link>
      <pubDate>Mon, 22 Oct 2012 06:59:09 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/applying-sampling-theory-to-real-time-graphics/</guid>
      <description>Previous article in the series: Signal Processing Primer
Computer graphics is a field that constantly deals with discrete sampling and reconstruction of signals, although you might not be aware of it yet. This article focuses on the ways in which sampling theory can be applied to some of the common tasks routinely performed in graphics and 3D rendering.
Image Scaling The concepts of sampling theory can are most easily applicable to graphics in the form of image scaling.</description>
    </item>
    
    <item>
      <title>Signal Processing Primer</title>
      <link>https://therealmjp.github.io/posts/signal-processing-primer/</link>
      <pubDate>Mon, 15 Oct 2012 08:20:18 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/signal-processing-primer/</guid>
      <description>For a theoretical understanding of aliasing and anti-aliasing, we can turn to the fields of signal processing[1] and sampling theory[2]. This article will explain some of the basics of these two related field in my own words, taking a more theoretical point of view. In the following article the concepts covered here will be used to analyze common aspects of real-time graphics, so that we can describe them in terms of signal processing.</description>
    </item>
    
    <item>
      <title>Upcoming Series on Signal Processing and MSAA</title>
      <link>https://therealmjp.github.io/posts/upcoming-series-on-signal-processing-and-msaa/</link>
      <pubDate>Mon, 15 Oct 2012 08:00:47 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/upcoming-series-on-signal-processing-and-msaa/</guid>
      <description>Aliasing is everywhere in graphics. Almost everything we do uses discrete sampling, which means almost everything can produce a variety of aliasing artifacts. The folks in the film industry have historically taken a “no aliasing allowed” stance in their work, but in real-time graphics we’re still producing games with more sparkling and shimmering than a glitzy prom dress. If we’re going to do anything about that problem, I think it’s important that we all try to have at least a basic understanding of signal processing.</description>
    </item>
    
    <item>
      <title>OpenGL Insights</title>
      <link>https://therealmjp.github.io/posts/opengl-insights/</link>
      <pubDate>Mon, 06 Aug 2012 04:50:49 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/opengl-insights/</guid>
      <description>Some time ago Charles de Rousiers adapted my Bokeh Depth of Field sample to OpenGL, and we contributed it as a chapter to the recently-released OpenGL Insights. Bokeh is still an ongoing area of R&amp;amp;D for myself, and hopefully I&amp;rsquo;ll be able to share some more improvements and optimizations once my current project is announced or released.
There&amp;rsquo;s going to be an author meet-up/book signing a the CRC Press SIGGRAPH booth (#929) this Tuesday from 2-3PM, and I&amp;rsquo;ll most likely be stopping by.</description>
    </item>
    
    <item>
      <title>Looking for a job?</title>
      <link>https://therealmjp.github.io/posts/looking-for-a-job/</link>
      <pubDate>Sat, 28 Apr 2012 22:55:10 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/looking-for-a-job/</guid>
      <description>My company, Ready At Dawn Studios, is hiring pretty much across the board. Our jobs page has the full details, but the gist of it is that we&amp;rsquo;re working on a new AAA IP for a next-generation home console. I can&amp;rsquo;t really say more than that about the project, but I will say that we&amp;rsquo;re doing some *really* exciting work in terms of graphics. If you&amp;rsquo;re interested, send your resume to jobs[at]readyatdawn.</description>
    </item>
    
    <item>
      <title>A quick note on shader compilers</title>
      <link>https://therealmjp.github.io/posts/a-quick-note-on-shader-compilers/</link>
      <pubDate>Sat, 14 Apr 2012 04:56:04 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/a-quick-note-on-shader-compilers/</guid>
      <description>This morning I was wrestling with a particularly complicated compute shader, which was taking just shy of 10 minutes to compile using D3DCompiler_43 from the June 2010 DirectX SDK. After a few failed attempts to speed it up by rearranging the code, I figured I&amp;rsquo;d try it out with the new version of the compiler that comes with the Windows 8 SDK. I wasn&amp;rsquo;t expecting any miracles, but to my surprise it compiled my shader in about 45 seconds!</description>
    </item>
    
    <item>
      <title>Light Indexed Deferred Rendering</title>
      <link>https://therealmjp.github.io/posts/light-indexed-deferred-rendering/</link>
      <pubDate>Sun, 01 Apr 2012 02:53:53 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/light-indexed-deferred-rendering/</guid>
      <description>There&amp;rsquo;s been a bit of a stir on the Internet lately due to AMD&amp;rsquo;s recent Leo demo, which was recently revealed to be using a modern twist on Light Indexed Deferred Rendering. The idea of light indexed deferred has always been pretty appealing, since it gives you some of the advantages of deferred rendering (namely using the GPU to decide which lights affect each pixel) while still letting you use forward rendering to actually apply the lighting to each surface.</description>
    </item>
    
    <item>
      <title>10 Things That Need To Die For Next-Gen</title>
      <link>https://therealmjp.github.io/posts/things-that-need-to-die/</link>
      <pubDate>Tue, 06 Dec 2011 09:54:34 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/things-that-need-to-die/</guid>
      <description>Lately I&amp;rsquo;ve been thinking about things in graphics that have long worn out their welcome, and I started a list of techniques that I hope will be nowhere in sight once everyone moves on to next-gen console hardware (or starts truly exploiting high-end PC hardware). Here they are, in no particular order:
 Phong/Blinn-Phong - we need more expressive BRDF&amp;rsquo;s for our materials, and these guys are getting in the way.</description>
    </item>
    
    <item>
      <title>GPU Profiling in DX11 with Queries</title>
      <link>https://therealmjp.github.io/posts/profiling-in-dx11-with-queries/</link>
      <pubDate>Thu, 13 Oct 2011 08:59:37 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/profiling-in-dx11-with-queries/</guid>
      <description>For profiling GPU performance on the PC, there aren&amp;rsquo;t too many options. AMD&amp;rsquo;s GPU PerfStudio and Nvidia&amp;rsquo;s Parallel Nsight can be pretty handy due to their ability to query hardware performance counters and display the data, but they only work on each vendor&amp;rsquo;s respective hardware. You also might want to integrate some GPU performance numbers into your own internal profiling systems, in which case those tools aren&amp;rsquo;t going to be of much use.</description>
    </item>
    
    <item>
      <title>Average luminance calculation using a compute shader</title>
      <link>https://therealmjp.github.io/posts/average-luminance-compute-shader/</link>
      <pubDate>Wed, 10 Aug 2011 09:31:03 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/average-luminance-compute-shader/</guid>
      <description>A common part of most HDR rendering pipelines is some form of average luminance calculation. Typically it&amp;rsquo;s used to implement Reinhard&amp;rsquo;s method of image calibration, which is to map the geometric mean of luminance (log average) to some &amp;ldquo;key value&amp;rdquo;. This, combined with some time-based adaptation, allows for a reasonable approximation of auto-exposure or human eye adaptation.
In the old days of DX9, the average luminance calculation was usually done repeatedly downscaling a luminance texture as if generating mipmaps.</description>
    </item>
    
    <item>
      <title>I am officially a published author</title>
      <link>https://therealmjp.github.io/posts/i-am-officially-a-published-author/</link>
      <pubDate>Fri, 05 Aug 2011 06:04:11 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/i-am-officially-a-published-author/</guid>
      <description>I recently collaborated with fellow DX MVP&amp;rsquo;s Jason Zink and Jack Hoxley to write a D3D11-focused book entitled Practical Rendering and Computation with Direct3D 11, which just came up for sale on Amazon today. I wrote the HLSL and Deferred Rendering chapters in particular. All of the code samples are up on the Hieroglyph 3 CodePlex site, if you want to get an idea of the content. Or you can just take my word for it that it&amp;rsquo;s awesome.</description>
    </item>
    
    <item>
      <title>Anamorphic lens flares: the lens flare of the 2010&#39;s?</title>
      <link>https://therealmjp.github.io/posts/lens-flares/</link>
      <pubDate>Fri, 10 Jun 2011 06:57:41 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/lens-flares/</guid>
      <description>Since the dawn of time, the greatest struggle of the graphics programmer is to ensure that bright stuff looks really damn bright. We&amp;rsquo;re stuck with displays that have a limited displayable range, which means it&amp;rsquo;s fallen upon us to come up with new hacks and tricks to make sure the player at least feels like he&amp;rsquo;s blinded by the sun, even if we can&amp;rsquo;t really cause physical damage to their eyes (if only!</description>
    </item>
    
    <item>
      <title>Bokeh II: The Sequel</title>
      <link>https://therealmjp.github.io/posts/bokeh-ii-the-sequel/</link>
      <pubDate>Wed, 20 Apr 2011 06:59:20 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/bokeh-ii-the-sequel/</guid>
      <description>After I finished the bokeh sample, there were a few remaining issues that I wanted to tackle before I was ready to call it &amp;ldquo;totally awesome&amp;rdquo; and move on with my life.
Good blur - in the last sample I used either a 2-pass blur on a poisson disc performed at full resolution, or a bilateral Gaussian blur performed at &amp;frac14; resolution (both done in a pixel shader). The former is nice because it gives you variable filter width per-pixel, but you get some ugly noise-like artifacts due to insufficient sampling.</description>
    </item>
    
    <item>
      <title>Crashes on Nvidia hardware</title>
      <link>https://therealmjp.github.io/posts/crashes-on-nvidia-hardware/</link>
      <pubDate>Sat, 26 Mar 2011 07:23:30 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/crashes-on-nvidia-hardware/</guid>
      <description>A few people have told me that my past two samples (Bokeh and RadiosityDX11) were crashing on Nvidia GPU&amp;rsquo;s, which I verified myself on my coworker&amp;rsquo;s GTX 470. The crash appears to be a driver bug, since it happens deep in the Nvidia runtime DLL on a worker thread and also because it works fine on AMD hardware and the REF device. This morning we managed to narrow it down to the shadow map filtering shader code (shader code can crash drivers apparently, who knew?</description>
    </item>
    
    <item>
      <title>How To Fake Bokeh (And Make It Look Pretty Good)</title>
      <link>https://therealmjp.github.io/posts/bokeh/</link>
      <pubDate>Mon, 28 Feb 2011 08:18:35 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/bokeh/</guid>
      <description>Before I bought a decent DSLR camera and started putting it in manual mode, I never really noticed bokeh that much. I always just equated out-of-focus with blur, and that was that. But now that I&amp;rsquo;ve started noticing, I can&amp;rsquo;t stop seeing it everywhere. And now every time I see depth of field effects in a game that doesn&amp;rsquo;t have bokeh, it just looks wrong. A disc blur or even Gaussian blur is fine for approximating the look of out-0f-focus areas that are mostly low-frequency, but the hot spots just don&amp;rsquo;t look right at all (especially if you don&amp;rsquo;t do it in HDR).</description>
    </item>
    
    <item>
      <title>Radiosity, DX11 Style</title>
      <link>https://therealmjp.github.io/posts/radiosity-dx11-style/</link>
      <pubDate>Mon, 31 Jan 2011 08:08:09 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/radiosity-dx11-style/</guid>
      <description>Radiosity isn&amp;rsquo;t exactly new. According to Wikipedia it&amp;rsquo;s been used for rendering since the early 80&amp;rsquo;s, and this page looks like it may have been the first web page on the Internet. The basic premise is dead simple: for each point where you want to bake lighting (typically either a texel in a lightmap, or a vertex in a mesh), render the rest of the scene and any exterior light sources (skydome, area lights, sun, whatever) in all directions within a hemisphere surrounding the surface normal at that point.</description>
    </item>
    
    <item>
      <title>Position From Depth in GLSL</title>
      <link>https://therealmjp.github.io/posts/position-from-depth-glsl-style/</link>
      <pubDate>Sun, 09 Jan 2011 01:47:45 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/position-from-depth-glsl-style/</guid>
      <description>Commenter &amp;ldquo;Me&amp;rdquo; was kind enough to share his GLSL implementation of a deferred point light shader, which makes use of one of the methods I previously posted for reconstructing position from depth. So I figured I&amp;rsquo;d post it here, for all of you unfortunate enough to be stuck with writing shaders in GLSL. :P
// deferred shading VERTEX (GEOMETRY) varying vec3 normalv, posv; void main( void ) { normalv = ( gl_NormalMatrix * gl_Normal ).</description>
    </item>
    
    <item>
      <title>Conservative Depth Output (and Other Lesser-Known D3D11 Features)</title>
      <link>https://therealmjp.github.io/posts/d3d11-features/</link>
      <pubDate>Mon, 15 Nov 2010 02:24:48 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d11-features/</guid>
      <description>D3D11 came with a whole bunch of new big-ticket features that received plenty of attention and publicity. Things like tessellation, compute shaders, and multithreaded command submission have the subject of many presentations, discussion, and sample apps. However D3D11 also came with a few other features that allow more &amp;ldquo;traditional&amp;rdquo; rendering approaches to benefit from the increased programmability of graphics hardware. Unfortunately most of them have gone relatively unnoticed, which isn&amp;rsquo;t surprising when you consider that most of them have little or no documentation, (much like some of the cool stuff that came in D3D10.</description>
    </item>
    
    <item>
      <title>Position From Depth 3: Back In The Habit</title>
      <link>https://therealmjp.github.io/posts/position-from-depth-3/</link>
      <pubDate>Mon, 06 Sep 2010 07:11:52 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/position-from-depth-3/</guid>
      <description>A friend of mine once told me that you could use &amp;ldquo;back in the habit&amp;rdquo; as the subtitle for any movie sequel. I think it works.
So a lot of people still have trouble with reconstructing position from depth thing, judging by the emails I get and also the threads I see in the gamedev forums made by people who read my earlier blog posts. Can&amp;rsquo;t say I blame them&amp;hellip;it&amp;rsquo;s pretty tricky, and easy to screw up.</description>
    </item>
    
    <item>
      <title>Deferred MSAA</title>
      <link>https://therealmjp.github.io/posts/deferred-msaa/</link>
      <pubDate>Mon, 16 Aug 2010 08:57:37 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/deferred-msaa/</guid>
      <description>A long while ago I was looking into morphological antialiasing (MLAA) to see if I could somehow make it practical for a GPU that isn&amp;rsquo;t the latest monster from Nvidia or ATI. With MLAA most people talk about how nicely it cleans up edges (which it certainly does), but for me the really cool part is how it&amp;rsquo;s completely orthogonal to the technique used to render the image. It could have been rasterized and forward rendered, it could be the product of a deferred rendering, or it could even be ray-traced: in all cases the algorithm works the same.</description>
    </item>
    
    <item>
      <title>MSAA Sample Pattern Detector</title>
      <link>https://therealmjp.github.io/posts/msaa-sample-pattern-detector/</link>
      <pubDate>Wed, 07 Jul 2010 08:42:23 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-sample-pattern-detector/</guid>
      <description>Recently I&amp;rsquo;ve been experimenting with AA techniques, and one of the avenues I was pursuing required me to read back subsamples and use them to compute coverage. However I quickly ran into the problem that I didn&amp;rsquo;t know the sample position for a given subsample index. With FEATURE_LEVEL_10_1 and FEATURE_LEVEL_11 there are standard MSAA patterns you can use, but unfortunately I&amp;rsquo;m still stuck on a 10-level GPU so that wasn&amp;rsquo;t an option.</description>
    </item>
    
    <item>
      <title>A Closer Look At Tone Mapping</title>
      <link>https://therealmjp.github.io/posts/a-closer-look-at-tone-mapping/</link>
      <pubDate>Fri, 30 Apr 2010 08:47:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/a-closer-look-at-tone-mapping/</guid>
      <description>A few months ago my coworker showed me some slides from a presentation by tri-Ace regarding their game &amp;ldquo;Star Ocean 4&amp;rdquo;. The slides that really caught my eye were pages 90 to 96, where they discussed their approach to tone mapping. Instead of using the standard Reinhard tone mapping operator that everybody is so fond of, they decided to instead use curves based on actual specifications from different film types and CMOS sensors.</description>
    </item>
    
    <item>
      <title>Attack of the depth buffer</title>
      <link>https://therealmjp.github.io/posts/attack-of-the-depth-buffer/</link>
      <pubDate>Tue, 23 Mar 2010 07:42:36 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/attack-of-the-depth-buffer/</guid>
      <description>In these exciting modern times, people get a lot of mileage out of their depth buffers. Long gone are the days where we only use depth buffers for visibility and stenciling, as we now make use of the depth buffer to reconstruct world-space or view-space position of our geometry at any given pixel. This can be a powerful performance optimization, since the alternative is to output position into a &amp;ldquo;fat&amp;rdquo; floating-point buffer.</description>
    </item>
    
    <item>
      <title>D3D Performance and Debugging Tools Round-Up: PerfHUD</title>
      <link>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-perfhud/</link>
      <pubDate>Sun, 07 Mar 2010 05:42:44 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-perfhud/</guid>
      <description>Officially, Nvidia&amp;rsquo;s PerfHUD is a performance-monitoring and debugging application for use with Nvidia GPU&amp;rsquo;s. Unofficially, it&amp;rsquo;s pure awesomeness for a graphics programmer. While I personally find PIX to be a more useful tool when it comes to debugging, the fact that PerfHUD gives you hardware-specific details makes it infinitely more useful for profiling. At work I find myself using it every time there&amp;rsquo;s a performance issue on the PC. Here&amp;rsquo;s some of the things I like to do with it (warning, it&amp;rsquo;s a long list!</description>
    </item>
    
    <item>
      <title>D3D Performance and Debugging Tools Round-Up: PIX</title>
      <link>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-pix/</link>
      <pubDate>Mon, 15 Feb 2010 05:17:18 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-pix/</guid>
      <description>So at this point just everybody knows about knows about PIX. I mean it comes with the DirectX SDK, for crying out loud. This handy little program started its like as the Performance Investigator for Xbox (original Xbox, that is) and today is useful performance and debugging tool for both Windows and the Xbox 360. Since it&amp;rsquo;s a DirectX tool, most of the information you can gather from it is hardware-independent.</description>
    </item>
    
    <item>
      <title>New Series: D3D Performance and Debugging Tools Round-Up</title>
      <link>https://therealmjp.github.io/posts/new-series-d3d-performance-and-debugging-tools-round-up/</link>
      <pubDate>Mon, 15 Feb 2010 05:16:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/new-series-d3d-performance-and-debugging-tools-round-up/</guid>
      <description>Recently I&amp;rsquo;ve been spending a lot of time with the various performance and debugging utilities available for Direct3D, and I thought it might be useful to give a quick overview of what&amp;rsquo;s out there. I&amp;rsquo;m sure most people who do a lot of Direct3D/XNA work are aware of these tools, but probably aren&amp;rsquo;t familiar with all of the really cool things you can do with them.
What I&amp;rsquo;m going to do is run through each tool one at a time, and share some of the common use cases and show some screenshots of features I think are neat.</description>
    </item>
    
    <item>
      <title>Name Change</title>
      <link>https://therealmjp.github.io/posts/name-change/</link>
      <pubDate>Sat, 06 Feb 2010 23:22:13 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/name-change/</guid>
      <description>I got tired having an awkward mouthful of a blog name, so I decided to shorten it to something much snappier. Hence &amp;ldquo;MJP&amp;rsquo;s XNA Danger Zone&amp;rdquo; becomes simply &amp;ldquo;The Danger Zone&amp;rdquo;. I like it better already.
Actually the main reason for the change is that I&amp;rsquo;ve been taking a break from the XNA stuff so that I can finally play around with DX11 a bit. In fact I&amp;rsquo;ve been working on a simple and flexible DX11 sample framework, so you may see a few DX11 samples from me in the future.</description>
    </item>
    
    <item>
      <title>Inferred Rendering</title>
      <link>https://therealmjp.github.io/posts/inferred-rendering/</link>
      <pubDate>Sun, 10 Jan 2010 17:30:10 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/inferred-rendering/</guid>
      <description>So like I said in my last post, I&amp;rsquo;ve been doing some research into Inferred Rendering. If you&amp;rsquo;re not familiar with the technique, Scott Kircher has the original paper and presentation materials hosted on his website. The main topic of the paper is what they call &amp;ldquo;Discontinuity Sensitive Filtering&amp;rdquo;, or &amp;ldquo;DSF&amp;rdquo; for short. Basically it&amp;rsquo;s standard 2x2 bilinear filtering, except in addition to sampling the texture you&amp;rsquo;re interested in you also sample what they call a a &amp;ldquo;DSF buffer&amp;rdquo; containing depth, an instance ID (semi-unique for each instance rendering on-screen), and a normal ID (a semi-unique value identifying areas where the normals are continuous).</description>
    </item>
    
    <item>
      <title>Correcting XNA&#39;s Gamma Correction</title>
      <link>https://therealmjp.github.io/posts/correcting-xnas-gamma-correction/</link>
      <pubDate>Thu, 31 Dec 2009 22:31:58 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/correcting-xnas-gamma-correction/</guid>
      <description>One thing I never used to pay attention to is gamma correction. This is mainly because it rarely gets mentioned, and also because you can usually get pretty good results without ever even thinking about it. However it only took a few days at my new job for me to realize just how essential it is if you want professional-quality results.
Lately I&amp;rsquo;ve been doing some research into inferred rendering (more on that later), and while working up a prototype renderer in XNA I decided that I would (for once) be gamma-correct throughout the pipeline.</description>
    </item>
    
    <item>
      <title>More Post-Processing Tricks: Lens Flare</title>
      <link>https://therealmjp.github.io/posts/more-post-processing-tricks-lens-flare/</link>
      <pubDate>Tue, 15 Dec 2009 08:53:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/more-post-processing-tricks-lens-flare/</guid>
      <description>I was playing Killzone 2 the other day, which reminded me of the lens flare trick they used. Unlike most games, which use some sprites controlled by an occlusion query, they applied the effect as a post-process similar to bloom. The upside is that it works for all bright areas and not pre-defined areas (the sun), and you don&amp;rsquo;t have to do occlusion queries or anything like that since that&amp;rsquo;s handled automatically.</description>
    </item>
    
    <item>
      <title>Two Samples For The Price Of One</title>
      <link>https://therealmjp.github.io/posts/two-samples/</link>
      <pubDate>Sun, 06 Dec 2009 04:22:29 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/two-samples/</guid>
      <description>Today I have two XNA samples fresh out of the oven: a Motion Blur Sample, and Depth Of Field Sample. I figure all of the kids these days wanna add fancy post-processing tricks to their games, right? The motion blur sample shows you how to do camera motion blur using a depth buffer, or full object motion blur using a velocity buffer. The depth of field sample shows you how to do a standard blur-based DOF, a slightly-smarter blur-based DOF that doesn&amp;rsquo;t blur across edges, and the somewhat more physically accurate disc blur approach.</description>
    </item>
    
    <item>
      <title>New Tutorial: Using PIX With XNA</title>
      <link>https://therealmjp.github.io/posts/pix-with-xna/</link>
      <pubDate>Fri, 16 Oct 2009 15:49:13 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/pix-with-xna/</guid>
      <description>Ladies and gentlemen, I present you with the most epic of tutorials: Using PIX With XNA. This 37-page monster teaches PIX for the XNA programmer, and includes an in-depth explanation of the XNA/D3D9 relationship as well as 6 excercises that show you the how to solve common problems (full source code and XNA 3.1 projects included). I sure hope somebody finds this thing useful&amp;hellip;it took me forever to write this thing.</description>
    </item>
    
    <item>
      <title>Scintillating Snippets: Storing Normals Using Spherical Coordinates</title>
      <link>https://therealmjp.github.io/posts/storing-normals-using-spherical-coordinates/</link>
      <pubDate>Wed, 17 Jun 2009 16:36:06 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/storing-normals-using-spherical-coordinates/</guid>
      <description>Update: n00body posted this link in the comments, which is way more in-depth than my post. Check it out!
If you&amp;rsquo;ve ever implemented a deferred renderer, you know that one of the important points is keeping your G-Buffer small enough as to be reasonable in terms of bandwidth and your number of render targets. Thanks to that constant struggle between good and evil, people have come up with some reasonable clever approaches towards packing necessary attributes in your G-Buffer.</description>
    </item>
    
    <item>
      <title>What&#39;s good on the menu, waiter?</title>
      <link>https://therealmjp.github.io/posts/whats-good-on-the-menu-waiter/</link>
      <pubDate>Wed, 20 May 2009 16:28:39 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/whats-good-on-the-menu-waiter/</guid>
      <description>I remember reading someone say on gamedev.net that at some point everyone tries to write their own UI system, and usually gets it wrong. Apparently he&amp;rsquo;s right (or at least about the first part), because I&amp;rsquo;ve gone ahead and written a menu/UI system. While it initially started out as part of the engine/framework I&amp;rsquo;ve been working on for my game, as I worked on it I decided it might be better off if I decoupled it from the rest of the engine components and made it a standalone library/editor package so that other people could make use of it.</description>
    </item>
    
    <item>
      <title>Reconstructing Position From Depth, Continued</title>
      <link>https://therealmjp.github.io/posts/reconstructing-position-from-depth-continued/</link>
      <pubDate>Tue, 05 May 2009 20:09:33 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/reconstructing-position-from-depth-continued/</guid>
      <description>Picking up where I left off here&amp;hellip;
As I mentioned, you can also reconstruct a world-space position using the frustum ray technique. The first step is that you need your frustum corners to be rotated so that they match the current orientation of your camera. You can do this by transforming the frustum corners by a &amp;ldquo;camera world matrix&amp;rdquo;, which is a matrix representing the camera&amp;rsquo;s position and orientation in world-space.</description>
    </item>
    
    <item>
      <title>Undo and Redo: Take 2</title>
      <link>https://therealmjp.github.io/posts/undo-and-redo-take-2/</link>
      <pubDate>Thu, 30 Apr 2009 19:37:03 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/undo-and-redo-take-2/</guid>
      <description>Please excuse the rhyming in the title&amp;hellip;sometimes I just can&amp;rsquo;t help myself. It&amp;rsquo;s a problem.
A few weeks ago I started working on a super-duper-secret project (to be revealed soon), a big part of which was a new editor. Since I&amp;rsquo;m the kind of guy who gets all worked up about having proper undo and redo support, I took the opportunity to make it an up-front part of my design rather than just shoving it in afterwords.</description>
    </item>
    
    <item>
      <title>There&#39;s More Than One Way To Defer A Renderer</title>
      <link>https://therealmjp.github.io/posts/theres-more-than-one-way-to-defer-a-renderer/</link>
      <pubDate>Fri, 27 Mar 2009 19:21:49 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/theres-more-than-one-way-to-defer-a-renderer/</guid>
      <description>While the idea of deferred shading/deferred rendering isn&amp;rsquo;t quite as hot as it was year or two ago (OMG, Killzone 2 uses deferred rendering!), it&amp;rsquo;s still a cool idea that gets discussed rather often. People generally tend to be attracted to way a &amp;ldquo;pure&amp;rdquo; deferred renderer neatly and cleanly separates your geometry from your lighting, as well as the idea of being able to throw lights everywhere in their scene. However as anyone who&amp;rsquo;s done a little bit of research into the topic surely knows, it comes with a few drawbacks.</description>
    </item>
    
    <item>
      <title>Scintillating Snippets: Reconstructing Position From Depth</title>
      <link>https://therealmjp.github.io/posts/reconstructing-position-from-depth/</link>
      <pubDate>Tue, 10 Mar 2009 19:06:31 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/reconstructing-position-from-depth/</guid>
      <description>There are times I wish I&amp;rsquo;d never responded to this thread over at GDnet, simply because of the constant stream of PM&amp;rsquo;s that I still get about it. Wouldn&amp;rsquo;t it be nice if I could just pull out all the important bits, stick it on some blog, and then link everyone to it? You&amp;rsquo;re right, it would be!
First things first: what am I talking about? I&amp;rsquo;m talking about something that finds great use for deferred rendering: reconstructing the 3D position of a previously-rendered pixel (either in view-space or world-space) from a single depth value.</description>
    </item>
    
    <item>
      <title>Scintillating Snippets: Programatically Adding Content To A Content Project</title>
      <link>https://therealmjp.github.io/posts/snippet-content-project/</link>
      <pubDate>Thu, 19 Feb 2009 21:36:05 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/snippet-content-project/</guid>
      <description>One of the tools I made for my current project is a model editor. Basically it can import in .fbx or .x models, and then you can apply my custom effects, set parameters, set textures, and then save it using my custom model format I named &amp;ldquo;.jsm&amp;rdquo; (it&amp;rsquo;s just XML&amp;hellip;don&amp;rsquo;t tell anyone!). Anyway one of the neat features I wanted it to have was the ability to add a model to my game&amp;rsquo;s Content project so that you wouldn&amp;rsquo;t have to manually do it through Visual Studio.</description>
    </item>
    
    <item>
      <title>Deferred Cascaded Shadow Maps</title>
      <link>https://therealmjp.github.io/posts/deferred-cascaded-shadow-maps/</link>
      <pubDate>Wed, 18 Feb 2009 04:22:32 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/deferred-cascaded-shadow-maps/</guid>
      <description>For my next sample I was planning on extending my deferred shadow maps sample to implement cascaded shadow maps. I got an email asking about how to make the sample look decent with large viewing distances which is exactly the problem CSM&amp;rsquo;s solve. So I decided to bump up my plans a little early and get the code up and running. It&amp;rsquo;ll be a while before I get the write-up finished, but until then feel free to play around with code (PC and 360 projects included).</description>
    </item>
    
    <item>
      <title>Profiling Events vs. Virtual Functions On The 360</title>
      <link>https://therealmjp.github.io/posts/profiling-events/</link>
      <pubDate>Fri, 23 Jan 2009 17:31:19 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/profiling-events/</guid>
      <description>Over the past week or so I&amp;rsquo;ve been completely reworking my collision system in order to better decouple it from other areas of code, and also make it more flexible. One part I got stuck on for a bit was deciding on the mechanism to use for notifying owners of collision components when the component collides with something. I narrowed it down to two options:
 notify owners via the ICollisionOwner interface I was using  OR</description>
    </item>
    
    <item>
      <title>Deferred Shadow Maps Sample</title>
      <link>https://therealmjp.github.io/posts/deferred-shadow-maps-sample/</link>
      <pubDate>Tue, 20 Jan 2009 01:24:19 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/deferred-shadow-maps-sample/</guid>
      <description>Got a new sample ready, this one shows how you can defer shadow map calculations to a separate screen-space pass using a depth buffer. Check it out on Ziggyware!
 Comments: sam - Feb 4, 2009
This sample does not works for me. I see the blank screen. My Video card is GF 9800 GT. Alejandro Martinez - Feb 2, 2010
1./2. Points taken! 3. That&amp;rsquo;s quite a boost for the shadow map render and sampling (HW PCF or Ati&amp;rsquo;s Fetch4).</description>
    </item>
    
    <item>
      <title>Teach Your Effects A New Trick</title>
      <link>https://therealmjp.github.io/posts/teach-your-effects-a-new-trick/</link>
      <pubDate>Mon, 19 Jan 2009 19:51:51 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/teach-your-effects-a-new-trick/</guid>
      <description>The Effects Framework is a pretty damn awesome tool. However I&amp;rsquo;m afraid that&amp;rsquo;s not totally obvious to a lot of newbies, who either just don&amp;rsquo;t what it can do or haven&amp;rsquo;t been exposed to some of the situations where Effect&amp;rsquo;s can really come in handy.
One neat thing Effect&amp;rsquo;s can do that isn&amp;rsquo;t obvious from the documentation or samples is auto-generate variants of shaders for you based on the value of uniform parameters.</description>
    </item>
    
    <item>
      <title>Fun With Compiled Content</title>
      <link>https://therealmjp.github.io/posts/fun-with-compiled-content/</link>
      <pubDate>Sun, 18 Jan 2009 21:36:14 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/fun-with-compiled-content/</guid>
      <description>EDIT: I realized it was probably a much smarter idea to just zip up the code along with the designer code and upload it somewhere. So here it is.
Wouldn&amp;rsquo;t it be neat to be able to have a dialog you could pop up that would show all the pre-compiled content of a certain Type, with it all listed in a nice tree showing the directory structure? Of course it would!</description>
    </item>
    
    <item>
      <title>Book Recommendation: Real-Time Collision Detection</title>
      <link>https://therealmjp.github.io/posts/book-recommendation-real-time-collision-detection/</link>
      <pubDate>Sat, 17 Jan 2009 23:27:18 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/book-recommendation-real-time-collision-detection/</guid>
      <description>I just recently ordered and received Real-Time Collision Detection from Amazon, and it was worth every penny. Collision detection was never something I was never particularly interested in, and in that past I was always willing to just leave it all up to a physics package to handle. But as anyone else working on an XNA game for the 360 knows, a physics engine isn&amp;rsquo;t really a practical option this time around.</description>
    </item>
    
    <item>
      <title>Undo and Redo: Yes you have to implement it</title>
      <link>https://therealmjp.github.io/posts/undo-and-redo/</link>
      <pubDate>Fri, 19 Dec 2008 19:05:15 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/undo-and-redo/</guid>
      <description>A professional developer on the gamedev.net forums once said &amp;ldquo;if you&amp;rsquo;ve implemented Undo and Redo in your app, then you&amp;rsquo;re in the top 1% of applicants for a tools developer position&amp;rdquo;. That&amp;rsquo;s funny to me, because I have no idea how you could possibly have a useful tool without such a fundamental element of GUI application development. I mean&amp;hellip;people screw up. It&amp;rsquo;s nice for users to know that their mistake can go away with a single press of &amp;ldquo;ctrl+z&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>LogLuv Encoding for HDR</title>
      <link>https://therealmjp.github.io/posts/logluv-encoding-for-hdr/</link>
      <pubDate>Fri, 12 Dec 2008 17:00:59 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/logluv-encoding-for-hdr/</guid>
      <description>Okay so this marks the third time I&amp;rsquo;ve posted this blog entry somewhere. What can I say&amp;hellip;I like it! I also think it&amp;rsquo;s something useful for just about anyone trying to do HDR on the 360 through XNA, and I&amp;rsquo;m hoping some people will stumble upon it.
Designing an effective and performant HDR implementation for my game&amp;rsquo;s engine was a step that was complicated a bit by a few of the quirks of running XNA on the Xbox 360.</description>
    </item>
    
    <item>
      <title>Jamming to the oldies</title>
      <link>https://therealmjp.github.io/posts/oldies/</link>
      <pubDate>Fri, 12 Dec 2008 16:39:21 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/oldies/</guid>
      <description>Just wanted to post some links to old blog entries from gamedev.net&amp;hellip;
Working With Unicode in the Windows API
Don&amp;rsquo;t Cast Function Pointers (Unless You Really Know What You&amp;rsquo;re Doing)
Posting WM_DESTROY is *not* how you destroy a window</description>
    </item>
    
    <item>
      <title>Cleared for takeoff</title>
      <link>https://therealmjp.github.io/posts/cleared-for-takeoff/</link>
      <pubDate>Wed, 10 Dec 2008 21:22:13 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/cleared-for-takeoff/</guid>
      <description>Look out interwebs, I have a new blog to call my own!
*insert trumpet fanfare here*
Here&amp;rsquo;s what I plan on doing with it: -integrating some of the stuff I&amp;rsquo;ve been posting on gamedev.net and xnainfo.com in one place -put up some samples/tutorials/tools/code I&amp;rsquo;ve come up with -yammer on about JumpSwitch, the Xbox 360 game I&amp;rsquo;m working on -set up a page to show some sweet pics and vids of JumpSwitch, so everyone can see how awesome it is -post links to cool and helpful stuff I find -try to somewhat serious (not likely to happen)</description>
    </item>
    
  </channel>
</rss>