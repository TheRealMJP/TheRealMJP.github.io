<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DirectX 11 on The Danger Zone</title>
    <link>https://therealmjp.github.io/tags/directx-11/</link>
    <description>Recent content in DirectX 11 on The Danger Zone</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Feb 2014 06:58:04 +0000</lastBuildDate>
    
	<atom:link href="https://therealmjp.github.io/tags/directx-11/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Weighted Blended Order-Independent Transparency</title>
      <link>https://therealmjp.github.io/posts/weighted-blended-oit/</link>
      <pubDate>Tue, 04 Feb 2014 06:58:04 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/weighted-blended-oit/</guid>
      <description>http://mynameismjp.files.wordpress.com/2014/02/blendedoit.zip
Back in December, Morgan McGuire and Louis Bavoil published a paper called Weighted Blended Order-Independent Transparency. In case you haven&amp;rsquo;t read it yet (you really should!), it proposes an OIT scheme that uses a weighted blend of all surfaces that overlap a given pixel. In other words finalColor = w0 * c0 + w1 * c1 + w2 * c2&amp;hellip;etc. With a weighted blend the order of rendering no longer matters, which frees you from the never-ending nightmare of sorting.</description>
    </item>
    
    <item>
      <title>A Sampling of Shadow Techniques</title>
      <link>https://therealmjp.github.io/posts/shadow-maps/</link>
      <pubDate>Wed, 11 Sep 2013 07:45:40 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/shadow-maps/</guid>
      <description>A little over a year ago I was looking to overhaul our shadow rendering at work in order to improve overall quality, as well as simplify the workflow for the lighting artists (tweaking biases all day isn&amp;rsquo;t fun for anybody). After doing yet another round of research into modern shadow mapping techniques, I decided to do what I usually do and starting working on sample project that I could use as a platform for experimentation and comparison.</description>
    </item>
    
    <item>
      <title>HLSL User Defined Language for Notepad&#43;&#43;</title>
      <link>https://therealmjp.github.io/posts/hlsl-udl/</link>
      <pubDate>Mon, 05 Nov 2012 07:09:39 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/hlsl-udl/</guid>
      <description>When it comes to writing shaders, Notepad++ is currently my editor of choice. The most recent release of Notepad++ added version 2.0 of their User Defined Language (UDL) system, which adds quite a few improvements. I&amp;rsquo;ve been using an HLSL UDL file that I downloaded from somewhere else for a while now, and I decided to upgrade it to the 2.0 format and also make it work better for SM5.0 profiles.</description>
    </item>
    
    <item>
      <title>Experimenting with Reconstruction Filters for MSAA Resolve</title>
      <link>https://therealmjp.github.io/posts/msaa-resolve-filters/</link>
      <pubDate>Mon, 29 Oct 2012 07:33:31 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-resolve-filters/</guid>
      <description>Previous article in the series: A Quick Overview of MSAA
Update 8/26/2017: while working on The Order I improved upon the work described here, which I presented at SIGGRAPH 2015. I also created an updated MSAA + TAA filtering demo that you can find on GitHub, which just about completely supersedes the demo that&amp;rsquo;s linked at the end of the article. So make sure that you look at the new one as well!</description>
    </item>
    
    <item>
      <title>A Quick Overview of MSAA</title>
      <link>https://therealmjp.github.io/posts/msaa-overview/</link>
      <pubDate>Thu, 25 Oct 2012 07:03:27 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-overview/</guid>
      <description>Previous article in the series: Applying Sampling Theory to Real-Time Graphics
Updated 1/27/2016 - replaced the MSAA partial coverage image with a new image that illustrates subsamples being written to, as suggested by Simon Trümpler.
MSAA can be a bit complicated, due to the fact that it affects nearly the entire rasterization pipeline used in GPU’s. It’s also complicated because really understanding why it works requires at least a basic understanding of signal processing and image resampling.</description>
    </item>
    
    <item>
      <title>A quick note on shader compilers</title>
      <link>https://therealmjp.github.io/posts/a-quick-note-on-shader-compilers/</link>
      <pubDate>Sat, 14 Apr 2012 04:56:04 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/a-quick-note-on-shader-compilers/</guid>
      <description>This morning I was wrestling with a particularly complicated compute shader, which was taking just shy of 10 minutes to compile using D3DCompiler_43 from the June 2010 DirectX SDK. After a few failed attempts to speed it up by rearranging the code, I figured I&amp;rsquo;d try it out with the new version of the compiler that comes with the Windows 8 SDK. I wasn&amp;rsquo;t expecting any miracles, but to my surprise it compiled my shader in about 45 seconds!</description>
    </item>
    
    <item>
      <title>Light Indexed Deferred Rendering</title>
      <link>https://therealmjp.github.io/posts/light-indexed-deferred-rendering/</link>
      <pubDate>Sun, 01 Apr 2012 02:53:53 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/light-indexed-deferred-rendering/</guid>
      <description>There&amp;rsquo;s been a bit of a stir on the Internet lately due to AMD&amp;rsquo;s recent Leo demo, which was recently revealed to be using a modern twist on Light Indexed Deferred Rendering. The idea of light indexed deferred has always been pretty appealing, since it gives you some of the advantages of deferred rendering (namely using the GPU to decide which lights affect each pixel) while still letting you use forward rendering to actually apply the lighting to each surface.</description>
    </item>
    
    <item>
      <title>GPU Profiling in DX11 with Queries</title>
      <link>https://therealmjp.github.io/posts/profiling-in-dx11-with-queries/</link>
      <pubDate>Thu, 13 Oct 2011 08:59:37 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/profiling-in-dx11-with-queries/</guid>
      <description>For profiling GPU performance on the PC, there aren&amp;rsquo;t too many options. AMD&amp;rsquo;s GPU PerfStudio and Nvidia&amp;rsquo;s Parallel Nsight can be pretty handy due to their ability to query hardware performance counters and display the data, but they only work on each vendor&amp;rsquo;s respective hardware. You also might want to integrate some GPU performance numbers into your own internal profiling systems, in which case those tools aren&amp;rsquo;t going to be of much use.</description>
    </item>
    
    <item>
      <title>Average luminance calculation using a compute shader</title>
      <link>https://therealmjp.github.io/posts/average-luminance-compute-shader/</link>
      <pubDate>Wed, 10 Aug 2011 09:31:03 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/average-luminance-compute-shader/</guid>
      <description>A common part of most HDR rendering pipelines is some form of average luminance calculation. Typically it&amp;rsquo;s used to implement Reinhard&amp;rsquo;s method of image calibration, which is to map the geometric mean of luminance (log average) to some &amp;ldquo;key value&amp;rdquo;. This, combined with some time-based adaptation, allows for a reasonable approximation of auto-exposure or human eye adaptation.
In the old days of DX9, the average luminance calculation was usually done repeatedly downscaling a luminance texture as if generating mipmaps.</description>
    </item>
    
    <item>
      <title>I am officially a published author</title>
      <link>https://therealmjp.github.io/posts/i-am-officially-a-published-author/</link>
      <pubDate>Fri, 05 Aug 2011 06:04:11 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/i-am-officially-a-published-author/</guid>
      <description>I recently collaborated with fellow DX MVP&amp;rsquo;s Jason Zink and Jack Hoxley to write a D3D11-focused book entitled Practical Rendering and Computation with Direct3D 11, which just came up for sale on Amazon today. I wrote the HLSL and Deferred Rendering chapters in particular. All of the code samples are up on the Hieroglyph 3 CodePlex site, if you want to get an idea of the content. Or you can just take my word for it that it&amp;rsquo;s awesome.</description>
    </item>
    
    <item>
      <title>Bokeh II: The Sequel</title>
      <link>https://therealmjp.github.io/posts/bokeh-ii-the-sequel/</link>
      <pubDate>Wed, 20 Apr 2011 06:59:20 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/bokeh-ii-the-sequel/</guid>
      <description>After I finished the bokeh sample, there were a few remaining issues that I wanted to tackle before I was ready to call it &amp;ldquo;totally awesome&amp;rdquo; and move on with my life.
Good blur - in the last sample I used either a 2-pass blur on a poisson disc performed at full resolution, or a bilateral Gaussian blur performed at 1/4 resolution (both done in a pixel shader). The former is nice because it gives you variable filter width per-pixel, but you get some ugly noise-like artifacts due to insufficient sampling.</description>
    </item>
    
    <item>
      <title>How To Fake Bokeh (And Make It Look Pretty Good)</title>
      <link>https://therealmjp.github.io/posts/bokeh/</link>
      <pubDate>Mon, 28 Feb 2011 08:18:35 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/bokeh/</guid>
      <description>Before I bought a decent DSLR camera and started putting it in manual mode, I never really noticed bokeh that much. I always just equated out-of-focus with blur, and that was that. But now that I&amp;rsquo;ve started noticing, I can&amp;rsquo;t stop seeing it everywhere. And now every time I see depth of field effects in a game that doesn&amp;rsquo;t have bokeh, it just looks wrong. A disc blur or even Gaussian blur is fine for approximating the look of out-0f-focus areas that are mostly low-frequency, but the hot spots just don&amp;rsquo;t look right at all (especially if you don&amp;rsquo;t do it in HDR).</description>
    </item>
    
    <item>
      <title>Radiosity, DX11 Style</title>
      <link>https://therealmjp.github.io/posts/radiosity-dx11-style/</link>
      <pubDate>Mon, 31 Jan 2011 08:08:09 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/radiosity-dx11-style/</guid>
      <description>Radiosity isn&amp;rsquo;t exactly new. According to Wikipedia it&amp;rsquo;s been used for rendering since the early 80&amp;rsquo;s, and this page looks like it may have been the first web page on the Internet. The basic premise is dead simple: for each point where you want to bake lighting (typically either a texel in a lightmap, or a vertex in a mesh), render the rest of the scene and any exterior light sources (skydome, area lights, sun, whatever) in all directions within a hemisphere surrounding the surface normal at that point.</description>
    </item>
    
    <item>
      <title>Conservative Depth Output (and Other Lesser-Known D3D11 Features)</title>
      <link>https://therealmjp.github.io/posts/d3d11-features/</link>
      <pubDate>Mon, 15 Nov 2010 02:24:48 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d11-features/</guid>
      <description>D3D11 came with a whole bunch of new big-ticket features that received plenty of attention and publicity. Things like tessellation, compute shaders, and multithreaded command submission have the subject of many presentations, discussion, and sample apps. However D3D11 also came with a few other features that allow more &amp;ldquo;traditional&amp;rdquo; rendering approaches to benefit from the increased programmability of graphics hardware. Unfortunately most of them have gone relatively unnoticed, which isn&amp;rsquo;t surprising when you consider that most of them have little or no documentation, (much like some of the cool stuff that came in D3D10.</description>
    </item>
    
    <item>
      <title>Deferred MSAA</title>
      <link>https://therealmjp.github.io/posts/deferred-msaa/</link>
      <pubDate>Mon, 16 Aug 2010 08:57:37 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/deferred-msaa/</guid>
      <description>A long while ago I was looking into morphological antialiasing (MLAA) to see if I could somehow make it practical for a GPU that isn&amp;rsquo;t the latest monster from Nvidia or ATI. With MLAA most people talk about how nicely it cleans up edges (which it certainly does), but for me the really cool part is how it&amp;rsquo;s completely orthogonal to the technique used to render the image. It could have been rasterized and forward rendered, it could be the product of a deferred rendering, or it could even be ray-traced: in all cases the algorithm works the same.</description>
    </item>
    
    <item>
      <title>MSAA Sample Pattern Detector</title>
      <link>https://therealmjp.github.io/posts/msaa-sample-pattern-detector/</link>
      <pubDate>Wed, 07 Jul 2010 08:42:23 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-sample-pattern-detector/</guid>
      <description>Recently I&amp;rsquo;ve been experimenting with AA techniques, and one of the avenues I was pursuing required me to read back subsamples and use them to compute coverage. However I quickly ran into the problem that I didn&amp;rsquo;t know the sample position for a given subsample index. With FEATURE_LEVEL_10_1 and FEATURE_LEVEL_11 there are standard MSAA patterns you can use, but unfortunately I&amp;rsquo;m still stuck on a 10-level GPU so that wasn&amp;rsquo;t an option.</description>
    </item>
    
    <item>
      <title>A Closer Look At Tone Mapping</title>
      <link>https://therealmjp.github.io/posts/a-closer-look-at-tone-mapping/</link>
      <pubDate>Fri, 30 Apr 2010 08:47:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/a-closer-look-at-tone-mapping/</guid>
      <description>A few months ago my coworker showed me some slides from a presentation by tri-Ace regarding their game &amp;ldquo;Star Ocean 4&amp;rdquo;. The slides that really caught my eye were pages 90 to 96, where they discussed their approach to tone mapping. Instead of using the standard Reinhard tone mapping operator that everybody is so fond of, they decided to instead use curves based on actual specifications from different film types and CMOS sensors.</description>
    </item>
    
    <item>
      <title>Attack of the depth buffer</title>
      <link>https://therealmjp.github.io/posts/attack-of-the-depth-buffer/</link>
      <pubDate>Tue, 23 Mar 2010 07:42:36 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/attack-of-the-depth-buffer/</guid>
      <description>In these exciting modern times, people get a lot of mileage out of their depth buffers. Long gone are the days where we only use depth buffers for visibility and stenciling, as we now make use of the depth buffer to reconstruct world-space or view-space position of our geometry at any given pixel. This can be a powerful performance optimization, since the alternative is to output position into a &amp;ldquo;fat&amp;rdquo; floating-point buffer.</description>
    </item>
    
    <item>
      <title>D3D Performance and Debugging Tools Round-Up: PIX</title>
      <link>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-pix/</link>
      <pubDate>Mon, 15 Feb 2010 05:17:18 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-pix/</guid>
      <description>So at this point just everybody knows about knows about PIX. I mean it comes with the DirectX SDK, for crying out loud. This handy little program started its like as the Performance Investigator for Xbox (original Xbox, that is) and today is useful performance and debugging tool for both Windows and the Xbox 360. Since it&amp;rsquo;s a DirectX tool, most of the information you can gather from it is hardware-independent.</description>
    </item>
    
    <item>
      <title>New Series: D3D Performance and Debugging Tools Round-Up</title>
      <link>https://therealmjp.github.io/posts/new-series-d3d-performance-and-debugging-tools-round-up/</link>
      <pubDate>Mon, 15 Feb 2010 05:16:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/new-series-d3d-performance-and-debugging-tools-round-up/</guid>
      <description>Recently I&amp;rsquo;ve been spending a lot of time with the various performance and debugging utilities available for Direct3D, and I thought it might be useful to give a quick overview of what&amp;rsquo;s out there. I&amp;rsquo;m sure most people who do a lot of Direct3D/XNA work are aware of these tools, but probably aren&amp;rsquo;t familiar with all of the really cool things you can do with them.
What I&amp;rsquo;m going to do is run through each tool one at a time, and share some of the common use cases and show some screenshots of features I think are neat.</description>
    </item>
    
  </channel>
</rss>