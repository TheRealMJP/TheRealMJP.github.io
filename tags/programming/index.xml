<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Programming on The Danger Zone</title>
    <link>https://therealmjp.github.io/tags/programming/</link>
    <description>Recent content in Programming on The Danger Zone</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Feb 2014 06:58:04 +0000</lastBuildDate><atom:link href="https://therealmjp.github.io/tags/programming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Weighted Blended Order-Independent Transparency</title>
      <link>https://therealmjp.github.io/posts/weighted-blended-oit/</link>
      <pubDate>Tue, 04 Feb 2014 06:58:04 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/weighted-blended-oit/</guid>
      <description>http://mynameismjp.files.wordpress.com/2014/02/blendedoit.zip
Back in December, Morgan McGuire and Louis Bavoil published a paper called Weighted Blended Order-Independent Transparency. In case you haven&amp;rsquo;t read it yet (you really should!), it proposes an OIT scheme that uses a weighted blend of all surfaces that overlap a given pixel. In other words finalColor = w0 * c0 + w1 * c1 + w2 * c2&amp;hellip;etc. With a weighted blend the order of rendering no longer matters, which frees you from the never-ending nightmare of sorting.</description>
    </item>
    
    <item>
      <title>Sample Framework Updates</title>
      <link>https://therealmjp.github.io/posts/sample-framework-updates/</link>
      <pubDate>Tue, 17 Sep 2013 05:54:02 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/sample-framework-updates/</guid>
      <description>You may have noticed that my latest sample now has a proper UI instead of the homegrown sliders and keyboard toggles that I was using in my older samples. What you might not have noticed is that there&amp;rsquo;s a whole bunch of behind-the-scenes changes to go with that new UI! Before I ramble on, here&amp;rsquo;s a quick bullet-point list of the new features:
Switched to VS2012 and adopted a few C++11 features New UI back-end provided by AntTweakBar C#-based data-definition format for auto-generating UI Shader hot-swapping Better shader caching, and compressed cache files It occurred to me a little while ago that I could try to develop my framework into something that enables rapid prototyping, instead of just being some random bits of cobbled-together code.</description>
    </item>
    
    <item>
      <title>A Sampling of Shadow Techniques</title>
      <link>https://therealmjp.github.io/posts/shadow-maps/</link>
      <pubDate>Wed, 11 Sep 2013 07:45:40 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/shadow-maps/</guid>
      <description>A little over a year ago I was looking to overhaul our shadow rendering at work in order to improve overall quality, as well as simplify the workflow for the lighting artists (tweaking biases all day isn&amp;rsquo;t fun for anybody). After doing yet another round of research into modern shadow mapping techniques, I decided to do what I usually do and starting working on sample project that I could use as a platform for experimentation and comparison.</description>
    </item>
    
    <item>
      <title>DX11.2 Tiled Resources</title>
      <link>https://therealmjp.github.io/posts/dx11-2-tiled-resources/</link>
      <pubDate>Sat, 07 Sep 2013 06:21:28 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/dx11-2-tiled-resources/</guid>
      <description>Tiled resources seems to be the big-ticket item for the upcoming DX11.2 update. While the online documentation has some information about the new functions added to the API, there&amp;rsquo;s currently no information about the two tiers of tiled resource functionality being offered. Fortunately there is a sample app available that provides some clues. After poking around a bit last night, these were the differences that I noticed:
TIER2 supports MIN and MAX texture sampling modes that return the min or max of 4 neighboring texels.</description>
    </item>
    
    <item>
      <title>HLSL User Defined Language for Notepad&#43;&#43;</title>
      <link>https://therealmjp.github.io/posts/hlsl-udl/</link>
      <pubDate>Mon, 05 Nov 2012 07:09:39 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/hlsl-udl/</guid>
      <description>When it comes to writing shaders, Notepad++ is currently my editor of choice. The most recent release of Notepad++ added version 2.0 of their User Defined Language (UDL) system, which adds quite a few improvements. I&amp;rsquo;ve been using an HLSL UDL file that I downloaded from somewhere else for a while now, and I decided to upgrade it to the 2.0 format and also make it work better for SM5.0 profiles.</description>
    </item>
    
    <item>
      <title>Experimenting with Reconstruction Filters for MSAA Resolve</title>
      <link>https://therealmjp.github.io/posts/msaa-resolve-filters/</link>
      <pubDate>Mon, 29 Oct 2012 07:33:31 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-resolve-filters/</guid>
      <description>Previous article in the series: A Quick Overview of MSAA
Update 8/26/2017: while working on The Order I improved upon the work described here, which I presented at SIGGRAPH 2015. I also created an updated MSAA + TAA filtering demo that you can find on GitHub, which just about completely supersedes the demo that&amp;rsquo;s linked at the end of the article. So make sure that you look at the new one as well!</description>
    </item>
    
    <item>
      <title>OpenGL Insights</title>
      <link>https://therealmjp.github.io/posts/opengl-insights/</link>
      <pubDate>Mon, 06 Aug 2012 04:50:49 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/opengl-insights/</guid>
      <description>Some time ago Charles de Rousiers adapted my Bokeh Depth of Field sample to OpenGL, and we contributed it as a chapter to the recently-released OpenGL Insights. Bokeh is still an ongoing area of R&amp;amp;D for myself, and hopefully I&amp;rsquo;ll be able to share some more improvements and optimizations once my current project is announced or released.
There&amp;rsquo;s going to be an author meet-up/book signing a the CRC Press SIGGRAPH booth (#929) this Tuesday from 2-3PM, and I&amp;rsquo;ll most likely be stopping by.</description>
    </item>
    
    <item>
      <title>Light Indexed Deferred Rendering</title>
      <link>https://therealmjp.github.io/posts/light-indexed-deferred-rendering/</link>
      <pubDate>Sun, 01 Apr 2012 02:53:53 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/light-indexed-deferred-rendering/</guid>
      <description>There&amp;rsquo;s been a bit of a stir on the Internet lately due to AMD&amp;rsquo;s recent Leo demo, which was recently revealed to be using a modern twist on Light Indexed Deferred Rendering. The idea of light indexed deferred has always been pretty appealing, since it gives you some of the advantages of deferred rendering (namely using the GPU to decide which lights affect each pixel) while still letting you use forward rendering to actually apply the lighting to each surface.</description>
    </item>
    
    <item>
      <title>GPU Profiling in DX11 with Queries</title>
      <link>https://therealmjp.github.io/posts/profiling-in-dx11-with-queries/</link>
      <pubDate>Thu, 13 Oct 2011 08:59:37 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/profiling-in-dx11-with-queries/</guid>
      <description>For profiling GPU performance on the PC, there aren&amp;rsquo;t too many options. AMD&amp;rsquo;s GPU PerfStudio and Nvidia&amp;rsquo;s Parallel Nsight can be pretty handy due to their ability to query hardware performance counters and display the data, but they only work on each vendor&amp;rsquo;s respective hardware. You also might want to integrate some GPU performance numbers into your own internal profiling systems, in which case those tools aren&amp;rsquo;t going to be of much use.</description>
    </item>
    
    <item>
      <title>Average luminance calculation using a compute shader</title>
      <link>https://therealmjp.github.io/posts/average-luminance-compute-shader/</link>
      <pubDate>Wed, 10 Aug 2011 09:31:03 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/average-luminance-compute-shader/</guid>
      <description>A common part of most HDR rendering pipelines is some form of average luminance calculation. Typically it&amp;rsquo;s used to implement Reinhard&amp;rsquo;s method of image calibration, which is to map the geometric mean of luminance (log average) to some &amp;ldquo;key value&amp;rdquo;. This, combined with some time-based adaptation, allows for a reasonable approximation of auto-exposure or human eye adaptation.
In the old days of DX9, the average luminance calculation was usually done repeatedly downscaling a luminance texture as if generating mipmaps.</description>
    </item>
    
    <item>
      <title>Bokeh II: The Sequel</title>
      <link>https://therealmjp.github.io/posts/bokeh-ii-the-sequel/</link>
      <pubDate>Wed, 20 Apr 2011 06:59:20 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/bokeh-ii-the-sequel/</guid>
      <description>After I finished the bokeh sample, there were a few remaining issues that I wanted to tackle before I was ready to call it &amp;ldquo;totally awesome&amp;rdquo; and move on with my life.
Good blur - in the last sample I used either a 2-pass blur on a poisson disc performed at full resolution, or a bilateral Gaussian blur performed at 1/4 resolution (both done in a pixel shader). The former is nice because it gives you variable filter width per-pixel, but you get some ugly noise-like artifacts due to insufficient sampling.</description>
    </item>
    
    <item>
      <title>Crashes on Nvidia hardware</title>
      <link>https://therealmjp.github.io/posts/crashes-on-nvidia-hardware/</link>
      <pubDate>Sat, 26 Mar 2011 07:23:30 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/crashes-on-nvidia-hardware/</guid>
      <description>A few people have told me that my past two samples (Bokeh and RadiosityDX11) were crashing on Nvidia GPU&amp;rsquo;s, which I verified myself on my coworker&amp;rsquo;s GTX 470. The crash appears to be a driver bug, since it happens deep in the Nvidia runtime DLL on a worker thread and also because it works fine on AMD hardware and the REF device. This morning we managed to narrow it down to the shadow map filtering shader code (shader code can crash drivers apparently, who knew?</description>
    </item>
    
    <item>
      <title>How To Fake Bokeh (And Make It Look Pretty Good)</title>
      <link>https://therealmjp.github.io/posts/bokeh/</link>
      <pubDate>Mon, 28 Feb 2011 08:18:35 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/bokeh/</guid>
      <description>Before I bought a decent DSLR camera and started putting it in manual mode, I never really noticed bokeh that much. I always just equated out-of-focus with blur, and that was that. But now that I&amp;rsquo;ve started noticing, I can&amp;rsquo;t stop seeing it everywhere. And now every time I see depth of field effects in a game that doesn&amp;rsquo;t have bokeh, it just looks wrong. A disc blur or even Gaussian blur is fine for approximating the look of out-0f-focus areas that are mostly low-frequency, but the hot spots just don&amp;rsquo;t look right at all (especially if you don&amp;rsquo;t do it in HDR).</description>
    </item>
    
    <item>
      <title>Radiosity, DX11 Style</title>
      <link>https://therealmjp.github.io/posts/radiosity-dx11-style/</link>
      <pubDate>Mon, 31 Jan 2011 08:08:09 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/radiosity-dx11-style/</guid>
      <description>Radiosity isn&amp;rsquo;t exactly new. According to Wikipedia it&amp;rsquo;s been used for rendering since the early 80&amp;rsquo;s, and this page looks like it may have been the first web page on the Internet. The basic premise is dead simple: for each point where you want to bake lighting (typically either a texel in a lightmap, or a vertex in a mesh), render the rest of the scene and any exterior light sources (skydome, area lights, sun, whatever) in all directions within a hemisphere surrounding the surface normal at that point.</description>
    </item>
    
    <item>
      <title>Position From Depth in GLSL</title>
      <link>https://therealmjp.github.io/posts/position-from-depth-glsl-style/</link>
      <pubDate>Sun, 09 Jan 2011 01:47:45 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/position-from-depth-glsl-style/</guid>
      <description>Commenter &amp;ldquo;Me&amp;rdquo; was kind enough to share his GLSL implementation of a deferred point light shader, which makes use of one of the methods I previously posted for reconstructing position from depth. So I figured I&amp;rsquo;d post it here, for all of you unfortunate enough to be stuck with writing shaders in GLSL. :P
// deferred shading VERTEX (GEOMETRY) varying vec3 normalv, posv; void main( void ) { normalv = ( gl_NormalMatrix * gl_Normal ).</description>
    </item>
    
    <item>
      <title>Conservative Depth Output (and Other Lesser-Known D3D11 Features)</title>
      <link>https://therealmjp.github.io/posts/d3d11-features/</link>
      <pubDate>Mon, 15 Nov 2010 02:24:48 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d11-features/</guid>
      <description>D3D11 came with a whole bunch of new big-ticket features that received plenty of attention and publicity. Things like tessellation, compute shaders, and multithreaded command submission have the subject of many presentations, discussion, and sample apps. However D3D11 also came with a few other features that allow more &amp;ldquo;traditional&amp;rdquo; rendering approaches to benefit from the increased programmability of graphics hardware. Unfortunately most of them have gone relatively unnoticed, which isn&amp;rsquo;t surprising when you consider that most of them have little or no documentation, (much like some of the cool stuff that came in D3D10.</description>
    </item>
    
    <item>
      <title>Position From Depth 3: Back In The Habit</title>
      <link>https://therealmjp.github.io/posts/position-from-depth-3/</link>
      <pubDate>Mon, 06 Sep 2010 07:11:52 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/position-from-depth-3/</guid>
      <description>A friend of mine once told me that you could use &amp;ldquo;back in the habit&amp;rdquo; as the subtitle for any movie sequel. I think it works.
So a lot of people still have trouble with reconstructing position from depth thing, judging by the emails I get and also the threads I see in the gamedev forums made by people who read my earlier blog posts. Can&amp;rsquo;t say I blame them&amp;hellip;it&amp;rsquo;s pretty tricky, and easy to screw up.</description>
    </item>
    
    <item>
      <title>Deferred MSAA</title>
      <link>https://therealmjp.github.io/posts/deferred-msaa/</link>
      <pubDate>Mon, 16 Aug 2010 08:57:37 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/deferred-msaa/</guid>
      <description>A long while ago I was looking into morphological antialiasing (MLAA) to see if I could somehow make it practical for a GPU that isn&amp;rsquo;t the latest monster from Nvidia or ATI. With MLAA most people talk about how nicely it cleans up edges (which it certainly does), but for me the really cool part is how it&amp;rsquo;s completely orthogonal to the technique used to render the image. It could have been rasterized and forward rendered, it could be the product of a deferred rendering, or it could even be ray-traced: in all cases the algorithm works the same.</description>
    </item>
    
    <item>
      <title>MSAA Sample Pattern Detector</title>
      <link>https://therealmjp.github.io/posts/msaa-sample-pattern-detector/</link>
      <pubDate>Wed, 07 Jul 2010 08:42:23 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/msaa-sample-pattern-detector/</guid>
      <description>Recently I&amp;rsquo;ve been experimenting with AA techniques, and one of the avenues I was pursuing required me to read back subsamples and use them to compute coverage. However I quickly ran into the problem that I didn&amp;rsquo;t know the sample position for a given subsample index. With FEATURE_LEVEL_10_1 and FEATURE_LEVEL_11 there are standard MSAA patterns you can use, but unfortunately I&amp;rsquo;m still stuck on a 10-level GPU so that wasn&amp;rsquo;t an option.</description>
    </item>
    
    <item>
      <title>A Closer Look At Tone Mapping</title>
      <link>https://therealmjp.github.io/posts/a-closer-look-at-tone-mapping/</link>
      <pubDate>Fri, 30 Apr 2010 08:47:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/a-closer-look-at-tone-mapping/</guid>
      <description>A few months ago my coworker showed me some slides from a presentation by tri-Ace regarding their game &amp;ldquo;Star Ocean 4&amp;rdquo;. The slides that really caught my eye were pages 90 to 96, where they discussed their approach to tone mapping. Instead of using the standard Reinhard tone mapping operator that everybody is so fond of, they decided to instead use curves based on actual specifications from different film types and CMOS sensors.</description>
    </item>
    
    <item>
      <title>Attack of the depth buffer</title>
      <link>https://therealmjp.github.io/posts/attack-of-the-depth-buffer/</link>
      <pubDate>Tue, 23 Mar 2010 07:42:36 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/attack-of-the-depth-buffer/</guid>
      <description>In these exciting modern times, people get a lot of mileage out of their depth buffers. Long gone are the days where we only use depth buffers for visibility and stenciling, as we now make use of the depth buffer to reconstruct world-space or view-space position of our geometry at any given pixel. This can be a powerful performance optimization, since the alternative is to output position into a &amp;ldquo;fat&amp;rdquo; floating-point buffer.</description>
    </item>
    
    <item>
      <title>D3D Performance and Debugging Tools Round-Up: PerfHUD</title>
      <link>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-perfhud/</link>
      <pubDate>Sun, 07 Mar 2010 05:42:44 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-perfhud/</guid>
      <description>Officially, Nvidia&amp;rsquo;s PerfHUD is a performance-monitoring and debugging application for use with Nvidia GPU&amp;rsquo;s. Unofficially, it&amp;rsquo;s pure awesomeness for a graphics programmer. While I personally find PIX to be a more useful tool when it comes to debugging, the fact that PerfHUD gives you hardware-specific details makes it infinitely more useful for profiling. At work I find myself using it every time there&amp;rsquo;s a performance issue on the PC. Here&amp;rsquo;s some of the things I like to do with it (warning, it&amp;rsquo;s a long list!</description>
    </item>
    
    <item>
      <title>D3D Performance and Debugging Tools Round-Up: PIX</title>
      <link>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-pix/</link>
      <pubDate>Mon, 15 Feb 2010 05:17:18 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/d3d-performance-and-debugging-tools-round-up-pix/</guid>
      <description>So at this point just everybody knows about knows about PIX. I mean it comes with the DirectX SDK, for crying out loud. This handy little program started its like as the Performance Investigator for Xbox (original Xbox, that is) and today is useful performance and debugging tool for both Windows and the Xbox 360. Since it&amp;rsquo;s a DirectX tool, most of the information you can gather from it is hardware-independent.</description>
    </item>
    
    <item>
      <title>New Series: D3D Performance and Debugging Tools Round-Up</title>
      <link>https://therealmjp.github.io/posts/new-series-d3d-performance-and-debugging-tools-round-up/</link>
      <pubDate>Mon, 15 Feb 2010 05:16:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/new-series-d3d-performance-and-debugging-tools-round-up/</guid>
      <description>Recently I&amp;rsquo;ve been spending a lot of time with the various performance and debugging utilities available for Direct3D, and I thought it might be useful to give a quick overview of what&amp;rsquo;s out there. I&amp;rsquo;m sure most people who do a lot of Direct3D/XNA work are aware of these tools, but probably aren&amp;rsquo;t familiar with all of the really cool things you can do with them.
What I&amp;rsquo;m going to do is run through each tool one at a time, and share some of the common use cases and show some screenshots of features I think are neat.</description>
    </item>
    
    <item>
      <title>Inferred Rendering</title>
      <link>https://therealmjp.github.io/posts/inferred-rendering/</link>
      <pubDate>Sun, 10 Jan 2010 17:30:10 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/inferred-rendering/</guid>
      <description>So like I said in my last post, I&amp;rsquo;ve been doing some research into Inferred Rendering. If you&amp;rsquo;re not familiar with the technique, Scott Kircher has the original paper and presentation materials hosted on his website. The main topic of the paper is what they call &amp;ldquo;Discontinuity Sensitive Filtering&amp;rdquo;, or &amp;ldquo;DSF&amp;rdquo; for short. Basically it&amp;rsquo;s standard 2x2 bilinear filtering, except in addition to sampling the texture you&amp;rsquo;re interested in you also sample what they call a a &amp;ldquo;DSF buffer&amp;rdquo; containing depth, an instance ID (semi-unique for each instance rendering on-screen), and a normal ID (a semi-unique value identifying areas where the normals are continuous).</description>
    </item>
    
    <item>
      <title>Correcting XNA&#39;s Gamma Correction</title>
      <link>https://therealmjp.github.io/posts/correcting-xnas-gamma-correction/</link>
      <pubDate>Thu, 31 Dec 2009 22:31:58 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/correcting-xnas-gamma-correction/</guid>
      <description>One thing I never used to pay attention to is gamma correction. This is mainly because it rarely gets mentioned, and also because you can usually get pretty good results without ever even thinking about it. However it only took a few days at my new job for me to realize just how essential it is if you want professional-quality results.
Lately I&amp;rsquo;ve been doing some research into inferred rendering (more on that later), and while working up a prototype renderer in XNA I decided that I would (for once) be gamma-correct throughout the pipeline.</description>
    </item>
    
    <item>
      <title>More Post-Processing Tricks: Lens Flare</title>
      <link>https://therealmjp.github.io/posts/more-post-processing-tricks-lens-flare/</link>
      <pubDate>Tue, 15 Dec 2009 08:53:17 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/more-post-processing-tricks-lens-flare/</guid>
      <description>I was playing Killzone 2 the other day, which reminded me of the lens flare trick they used. Unlike most games, which use some sprites controlled by an occlusion query, they applied the effect as a post-process similar to bloom. The upside is that it works for all bright areas and not pre-defined areas (the sun), and you don&amp;rsquo;t have to do occlusion queries or anything like that since that&amp;rsquo;s handled automatically.</description>
    </item>
    
    <item>
      <title>Two Samples For The Price Of One</title>
      <link>https://therealmjp.github.io/posts/two-samples/</link>
      <pubDate>Sun, 06 Dec 2009 04:22:29 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/two-samples/</guid>
      <description>Today I have two XNA samples fresh out of the oven: a Motion Blur Sample, and Depth Of Field Sample. I figure all of the kids these days wanna add fancy post-processing tricks to their games, right? The motion blur sample shows you how to do camera motion blur using a depth buffer, or full object motion blur using a velocity buffer. The depth of field sample shows you how to do a standard blur-based DOF, a slightly-smarter blur-based DOF that doesn&amp;rsquo;t blur across edges, and the somewhat more physically accurate disc blur approach.</description>
    </item>
    
    <item>
      <title>New Tutorial: Using PIX With XNA</title>
      <link>https://therealmjp.github.io/posts/pix-with-xna/</link>
      <pubDate>Fri, 16 Oct 2009 15:49:13 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/pix-with-xna/</guid>
      <description>Ladies and gentlemen, I present you with the most epic of tutorials: Using PIX With XNA. This 37-page monster teaches PIX for the XNA programmer, and includes an in-depth explanation of the XNA/D3D9 relationship as well as 6 excercises that show you the how to solve common problems (full source code and XNA 3.1 projects included). I sure hope somebody finds this thing useful&amp;hellip;it took me forever to write this thing.</description>
    </item>
    
    <item>
      <title>Scintillating Snippets: Storing Normals Using Spherical Coordinates</title>
      <link>https://therealmjp.github.io/posts/storing-normals-using-spherical-coordinates/</link>
      <pubDate>Wed, 17 Jun 2009 16:36:06 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/storing-normals-using-spherical-coordinates/</guid>
      <description>Update: n00body posted this link in the comments, which is way more in-depth than my post. Check it out!
If you&amp;rsquo;ve ever implemented a deferred renderer, you know that one of the important points is keeping your G-Buffer small enough as to be reasonable in terms of bandwidth and your number of render targets. Thanks to that constant struggle between good and evil, people have come up with some reasonable clever approaches towards packing necessary attributes in your G-Buffer.</description>
    </item>
    
    <item>
      <title>What&#39;s good on the menu, waiter?</title>
      <link>https://therealmjp.github.io/posts/whats-good-on-the-menu-waiter/</link>
      <pubDate>Wed, 20 May 2009 16:28:39 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/whats-good-on-the-menu-waiter/</guid>
      <description>I remember reading someone say on gamedev.net that at some point everyone tries to write their own UI system, and usually gets it wrong. Apparently he&amp;rsquo;s right (or at least about the first part), because I&amp;rsquo;ve gone ahead and written a menu/UI system. While it initially started out as part of the engine/framework I&amp;rsquo;ve been working on for my game, as I worked on it I decided it might be better off if I decoupled it from the rest of the engine components and made it a standalone library/editor package so that other people could make use of it.</description>
    </item>
    
    <item>
      <title>Reconstructing Position From Depth, Continued</title>
      <link>https://therealmjp.github.io/posts/reconstructing-position-from-depth-continued/</link>
      <pubDate>Tue, 05 May 2009 20:09:33 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/reconstructing-position-from-depth-continued/</guid>
      <description>Picking up where I left off here&amp;hellip;
As I mentioned, you can also reconstruct a world-space position using the frustum ray technique. The first step is that you need your frustum corners to be rotated so that they match the current orientation of your camera. You can do this by transforming the frustum corners by a &amp;ldquo;camera world matrix&amp;rdquo;, which is a matrix representing the camera&amp;rsquo;s position and orientation in world-space.</description>
    </item>
    
    <item>
      <title>There&#39;s More Than One Way To Defer A Renderer</title>
      <link>https://therealmjp.github.io/posts/theres-more-than-one-way-to-defer-a-renderer/</link>
      <pubDate>Fri, 27 Mar 2009 19:21:49 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/theres-more-than-one-way-to-defer-a-renderer/</guid>
      <description>While the idea of deferred shading/deferred rendering isn&amp;rsquo;t quite as hot as it was year or two ago (OMG, Killzone 2 uses deferred rendering!), it&amp;rsquo;s still a cool idea that gets discussed rather often. People generally tend to be attracted to way a &amp;ldquo;pure&amp;rdquo; deferred renderer neatly and cleanly separates your geometry from your lighting, as well as the idea of being able to throw lights everywhere in their scene. However as anyone who&amp;rsquo;s done a little bit of research into the topic surely knows, it comes with a few drawbacks.</description>
    </item>
    
    <item>
      <title>Scintillating Snippets: Reconstructing Position From Depth</title>
      <link>https://therealmjp.github.io/posts/reconstructing-position-from-depth/</link>
      <pubDate>Tue, 10 Mar 2009 19:06:31 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/reconstructing-position-from-depth/</guid>
      <description>There are times I wish I&amp;rsquo;d never responded to this thread over at GDnet, simply because of the constant stream of PM&amp;rsquo;s that I still get about it. Wouldn&amp;rsquo;t it be nice if I could just pull out all the important bits, stick it on some blog, and then link everyone to it? You&amp;rsquo;re right, it would be!
First things first: what am I talking about? I&amp;rsquo;m talking about something that finds great use for deferred rendering: reconstructing the 3D position of a previously-rendered pixel (either in view-space or world-space) from a single depth value.</description>
    </item>
    
    <item>
      <title>Scintillating Snippets: Programatically Adding Content To A Content Project</title>
      <link>https://therealmjp.github.io/posts/snippet-content-project/</link>
      <pubDate>Thu, 19 Feb 2009 21:36:05 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/snippet-content-project/</guid>
      <description>One of the tools I made for my current project is a model editor. Basically it can import in .fbx or .x models, and then you can apply my custom effects, set parameters, set textures, and then save it using my custom model format I named &amp;ldquo;.jsm&amp;rdquo; (it&amp;rsquo;s just XML&amp;hellip;don&amp;rsquo;t tell anyone!). Anyway one of the neat features I wanted it to have was the ability to add a model to my game&amp;rsquo;s Content project so that you wouldn&amp;rsquo;t have to manually do it through Visual Studio.</description>
    </item>
    
    <item>
      <title>Deferred Cascaded Shadow Maps</title>
      <link>https://therealmjp.github.io/posts/deferred-cascaded-shadow-maps/</link>
      <pubDate>Wed, 18 Feb 2009 04:22:32 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/deferred-cascaded-shadow-maps/</guid>
      <description>For my next sample I was planning on extending my deferred shadow maps sample to implement cascaded shadow maps. I got an email asking about how to make the sample look decent with large viewing distances which is exactly the problem CSM&amp;rsquo;s solve. So I decided to bump up my plans a little early and get the code up and running. It&amp;rsquo;ll be a while before I get the write-up finished, but until then feel free to play around with code (PC and 360 projects included).</description>
    </item>
    
    <item>
      <title>Profiling Events vs. Virtual Functions On The 360</title>
      <link>https://therealmjp.github.io/posts/profiling-events/</link>
      <pubDate>Fri, 23 Jan 2009 17:31:19 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/profiling-events/</guid>
      <description>Over the past week or so I&amp;rsquo;ve been completely reworking my collision system in order to better decouple it from other areas of code, and also make it more flexible. One part I got stuck on for a bit was deciding on the mechanism to use for notifying owners of collision components when the component collides with something. I narrowed it down to two options:
notify owners via the ICollisionOwner interface I was using OR</description>
    </item>
    
    <item>
      <title>Deferred Shadow Maps Sample</title>
      <link>https://therealmjp.github.io/posts/deferred-shadow-maps-sample/</link>
      <pubDate>Tue, 20 Jan 2009 01:24:19 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/deferred-shadow-maps-sample/</guid>
      <description>Got a new sample ready, this one shows how you can defer shadow map calculations to a separate screen-space pass using a depth buffer. Check it out on Ziggyware!
Comments: sam - Feb 4, 2009
This sample does not works for me. I see the blank screen. My Video card is GF 9800 GT.
#### [Alejandro Martinez](http://www.gaspgames.com/www.battletennis.com &#34;amartinez1660@gmail.com&#34;) - Feb 2, 2010 1./2. Points taken! 3. That&amp;rsquo;s quite a boost for the shadow map render and sampling (HW PCF or Ati&amp;rsquo;s Fetch4).</description>
    </item>
    
    <item>
      <title>Teach Your Effects A New Trick</title>
      <link>https://therealmjp.github.io/posts/teach-your-effects-a-new-trick/</link>
      <pubDate>Mon, 19 Jan 2009 19:51:51 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/teach-your-effects-a-new-trick/</guid>
      <description>The Effects Framework is a pretty damn awesome tool. However I&amp;rsquo;m afraid that&amp;rsquo;s not totally obvious to a lot of newbies, who either just don&amp;rsquo;t what it can do or haven&amp;rsquo;t been exposed to some of the situations where Effect&amp;rsquo;s can really come in handy.
One neat thing Effect&amp;rsquo;s can do that isn&amp;rsquo;t obvious from the documentation or samples is auto-generate variants of shaders for you based on the value of uniform parameters.</description>
    </item>
    
    <item>
      <title>Fun With Compiled Content</title>
      <link>https://therealmjp.github.io/posts/fun-with-compiled-content/</link>
      <pubDate>Sun, 18 Jan 2009 21:36:14 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/fun-with-compiled-content/</guid>
      <description>EDIT: I realized it was probably a much smarter idea to just zip up the code along with the designer code and upload it somewhere. So here it is.
Wouldn&amp;rsquo;t it be neat to be able to have a dialog you could pop up that would show all the pre-compiled content of a certain Type, with it all listed in a nice tree showing the directory structure? Of course it would!</description>
    </item>
    
    <item>
      <title>Book Recommendation: Real-Time Collision Detection</title>
      <link>https://therealmjp.github.io/posts/book-recommendation-real-time-collision-detection/</link>
      <pubDate>Sat, 17 Jan 2009 23:27:18 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/book-recommendation-real-time-collision-detection/</guid>
      <description>I just recently ordered and received Real-Time Collision Detection from Amazon, and it was worth every penny. Collision detection was never something I was never particularly interested in, and in that past I was always willing to just leave it all up to a physics package to handle. But as anyone else working on an XNA game for the 360 knows, a physics engine isn&amp;rsquo;t really a practical option this time around.</description>
    </item>
    
    <item>
      <title>Undo and Redo: Yes you have to implement it</title>
      <link>https://therealmjp.github.io/posts/undo-and-redo/</link>
      <pubDate>Fri, 19 Dec 2008 19:05:15 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/undo-and-redo/</guid>
      <description>A professional developer on the gamedev.net forums once said &amp;ldquo;if you&amp;rsquo;ve implemented Undo and Redo in your app, then you&amp;rsquo;re in the top 1% of applicants for a tools developer position&amp;rdquo;. That&amp;rsquo;s funny to me, because I have no idea how you could possibly have a useful tool without such a fundamental element of GUI application development. I mean&amp;hellip;people screw up. It&amp;rsquo;s nice for users to know that their mistake can go away with a single press of &amp;ldquo;ctrl+z&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>LogLuv Encoding for HDR</title>
      <link>https://therealmjp.github.io/posts/logluv-encoding-for-hdr/</link>
      <pubDate>Fri, 12 Dec 2008 17:00:59 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/logluv-encoding-for-hdr/</guid>
      <description>Okay so this marks the third time I&amp;rsquo;ve posted this blog entry somewhere. What can I say&amp;hellip;I like it! I also think it&amp;rsquo;s something useful for just about anyone trying to do HDR on the 360 through XNA, and I&amp;rsquo;m hoping some people will stumble upon it.
Designing an effective and performant HDR implementation for my game&amp;rsquo;s engine was a step that was complicated a bit by a few of the quirks of running XNA on the Xbox 360.</description>
    </item>
    
    <item>
      <title>Jamming to the oldies</title>
      <link>https://therealmjp.github.io/posts/oldies/</link>
      <pubDate>Fri, 12 Dec 2008 16:39:21 +0000</pubDate>
      
      <guid>https://therealmjp.github.io/posts/oldies/</guid>
      <description>Just wanted to post some links to old blog entries from gamedev.net&amp;hellip;
Working With Unicode in the Windows API
Don&amp;rsquo;t Cast Function Pointers (Unless You Really Know What You&amp;rsquo;re Doing)
Posting WM_DESTROY is *not* how you destroy a window</description>
    </item>
    
  </channel>
</rss>
